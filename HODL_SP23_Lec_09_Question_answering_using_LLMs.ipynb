{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4ca8276-e829-4cff-8905-47534e4b4d4e",
      "metadata": {
        "id": "c4ca8276-e829-4cff-8905-47534e4b4d4e"
      },
      "source": [
        "# Using `text-davinci-003` to answer questions posed in natural language, using a custom dataset\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Credit**: Adapted from this [OpenAI notebook](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "Many use cases require us to respond to user questions with relevant and accurate answers. For example, a customer support chatbot may need to provide answers to common support questions.\n",
        "\n",
        "The GPT models have picked up a lot of general knowledge in training - remember GPT-3 was trained on 500 billion tokens! - but we often would like to have the model *use our own dataset or library* of more specific information to answer the questions (e.g., we would like our customer service chatbot to consult a library of service manuals when it answers a user question). We'd expect those tailored responses to be more helpful and accurate than generic responses uninformed by our specific data.\n",
        "\n",
        "In this notebook we will demonstrate a method for enabling `text-davinci-003` to answer questions using a library of text as a reference. We'll be using a dataset of Wikipedia articles about the 2020 Summer Olympic Games but the same approach can be used with a library of books, articles, documentation, service manuals, or much much more. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Let's get started by installing the openai python package\n"
      ],
      "metadata": {
        "id": "KYInMIG5qHYt"
      },
      "id": "KYInMIG5qHYt"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "HiJ-lzBu9bUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fab46d4-6143-4837-f466-e1c951abcf65"
      },
      "id": "HiJ-lzBu9bUg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we import the necessary packages, including numpy and pandas."
      ],
      "metadata": {
        "id": "tXxaQqeyqov6"
      },
      "id": "tXxaQqeyqov6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e3839a6-9146-4f60-b74b-19abbc24278d",
      "metadata": {
        "id": "9e3839a6-9146-4f60-b74b-19abbc24278d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's take a quick look at all the GPT models that are available ([Link](https://platform.openai.com/docs/models/gpt-3-5)). \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We will use the most recent version of the GPT family just before ChatGPT was released - the `text-davinci-003` model - in this colab.\n",
        "\n",
        "We can use the ChatGPT API as well (and we give a code example below) but since ChatGPT's training cutoff date is later, it \"knows\" about the 2020 Summer Olympics and the questions may be too easy. BTW, ChatGPT is referred to as `gpt-3.5-turbo` when making API calls.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2bUETiOrGBK"
      },
      "id": "Z2bUETiOrGBK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using pre-trained contextual embeddings as well. For that, we will use the latest/greatest `text-embedding-ada-002` model ([link](https://openai.com/blog/new-and-improved-embedding-model))."
      ],
      "metadata": {
        "id": "SoPF7Ukm9qrt"
      },
      "id": "SoPF7Ukm9qrt"
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\""
      ],
      "metadata": {
        "id": "4bylYKUdq8ug"
      },
      "id": "4bylYKUdq8ug",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's set the OpenAI API key. You can get yours [here](https://platform.openai.com/account/api-keys)."
      ],
      "metadata": {
        "id": "3F-ZfxvVrfze"
      },
      "id": "3F-ZfxvVrfze"
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"paste the key here\""
      ],
      "metadata": {
        "id": "BN4Av1k7-NrA"
      },
      "id": "BN4Av1k7-NrA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting without custom data"
      ],
      "metadata": {
        "id": "rgSVrSEHrled"
      },
      "id": "rgSVrSEHrled"
    },
    {
      "cell_type": "markdown",
      "id": "9312f62f-e208-4030-a648-71ad97aee74f",
      "metadata": {
        "id": "9312f62f-e208-4030-a648-71ad97aee74f"
      },
      "source": [
        "Before we try anything fancy, let's simply ask `text-davinci-003` a question on the 2020 Summer Olympics and see how it responds. \n",
        "\n",
        "First, we prepare the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a167516c-7c19-4bda-afa5-031aa0ae13bb",
      "metadata": {
        "id": "a167516c-7c19-4bda-afa5-031aa0ae13bb"
      },
      "outputs": [],
      "source": [
        "prompt = \"Who won the 2020 Summer Olympics men's high jump?\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we make the request to the model, using the openai API. [Documentation](https://platform.openai.com/docs/api-reference/completions/create?lang=python).\n"
      ],
      "metadata": {
        "id": "qKwMS3diCUCe"
      },
      "id": "qKwMS3diCUCe"
    },
    {
      "cell_type": "code",
      "source": [
        "result = openai.Completion.create(\n",
        "    prompt=prompt,              # well, your prompt goes here!\n",
        "    temperature=0,              # setting this to zero tells GPT to pick the most likely next word\n",
        "    max_tokens=300,             # the model will stop generating when it has generated 300 tokens\n",
        "    model=COMPLETIONS_MODEL     # which model you want to use\n",
        ")"
      ],
      "metadata": {
        "id": "0AfZ-QUVCRuL"
      },
      "id": "0AfZ-QUVCRuL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to pose the same question to ChatGPT instead of `text-davinci-003`\n",
        "# you can use this code\n",
        "# we aren't using ChatGPT in this example\n",
        "# since it \"knows\" about the 2020 Summer Olympics :)\n",
        "# unlike `text-davinci-003`\n",
        "\n",
        "# completion = openai.ChatCompletion.create(\n",
        "#   model=\"gpt-3.5-turbo\",\n",
        "#   messages=[\n",
        "#     {\"role\": \"user\", \"content\": prompt}\n",
        "#   ]\n",
        "# )\n",
        "\n",
        "# print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "CpcqXL3yAlTa"
      },
      "id": "CpcqXL3yAlTa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's extract just the text of the response."
      ],
      "metadata": {
        "id": "ELwoHkQmESF9"
      },
      "id": "ELwoHkQmESF9"
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"choices\"][0][\"text\"].strip(\" \\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHBC9o0JDFoj",
        "outputId": "309a6ffd-86b7-40d3-a027-c208b9a09eb2"
      },
      "id": "NHBC9o0JDFoj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marcelo Chierighini of Brazil won the gold medal in the men's high jump at the 2020 Summer Olympics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47204cce-a7d5-4c81-ab6e-53323026e08c",
      "metadata": {
        "id": "47204cce-a7d5-4c81-ab6e-53323026e08c"
      },
      "source": [
        "Let's Google this name and see if the answer is correct.\n",
        "\n",
        "<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Well, Marcelo is a **gold medalist swimmer, not a high jumper**!! \n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "Sounds like `text-davinci-003` could use some help. 😆\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \"Engineering\" the prompt to reduce hallucinations\n",
        "\n"
      ],
      "metadata": {
        "id": "PSQUCBO9s0J3"
      },
      "id": "PSQUCBO9s0J3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "One simple thing we can try right off the bat is to tell `text-davinci-003` to say \"I don't know\" if it doesn't know rather than make stuff up i.e., \"hallucinate\".\n",
        "\n",
        "\n",
        "How? By asking nicely? 😀 Well, almost.\n",
        "\n",
        "\n",
        "\n",
        "**By asking explicitly!**\n",
        "\n",
        "Let's modify our prompt as follows.\n"
      ],
      "metadata": {
        "id": "c8f8w4_jNqdh"
      },
      "id": "c8f8w4_jNqdh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5451371-17fe-4ef3-aa02-affcf4edb0e0",
      "metadata": {
        "id": "a5451371-17fe-4ef3-aa02-affcf4edb0e0"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
        "\n",
        "Q: Who won the 2020 Summer Olympics men's high jump?\n",
        "A:\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the explicit extra instruction in the above prompt: *as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\"*"
      ],
      "metadata": {
        "id": "QtjF92agtqz2"
      },
      "id": "QtjF92agtqz2"
    },
    {
      "cell_type": "code",
      "source": [
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ],
      "metadata": {
        "id": "FMZkGsg5tZr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "176aac4e-4b03-4456-ba3f-e687e3070f73"
      },
      "id": "FMZkGsg5tZr6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sorry, I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, it worked. The model is being humble and honest 👀."
      ],
      "metadata": {
        "id": "TcklGziptw_m"
      },
      "id": "TcklGziptw_m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is an interesting question as to why Instruct-GPT doesn't know this. Let's check the [cutoff date](https://help.openai.com/en/articles/6639781-do-the-openai-api-models-have-knowledge-of-current-events) for the training data."
      ],
      "metadata": {
        "id": "stSuIotb5Kh-"
      },
      "id": "stSuIotb5Kh-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using custom data"
      ],
      "metadata": {
        "id": "C-IRkW6NFSU8"
      },
      "id": "C-IRkW6NFSU8"
    },
    {
      "cell_type": "markdown",
      "id": "1af18d66-d47a-496d-ae5f-4c5d53caa434",
      "metadata": {
        "id": "1af18d66-d47a-496d-ae5f-4c5d53caa434"
      },
      "source": [
        "To help the model answer a question, we can provide custom data **in the prompt itself**. This extra information we provide in the prompt is referred to as **context**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manually enriching the prompt with custom data"
      ],
      "metadata": {
        "id": "R-d2d6tgF56x"
      },
      "id": "R-d2d6tgF56x"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first show how to do this by ***manually*** finding and adding information (that's relevant to the question) to the prompt."
      ],
      "metadata": {
        "id": "SkCRjOHPF_YP"
      },
      "id": "SkCRjOHPF_YP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will use the following passage on the 2020 Summer Olympics **high jump event** taken from Wikipedia as context:\n",
        ">The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium.\n",
        "33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places \n",
        "to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021).\n",
        "Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following\n",
        "a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance\n",
        "where the athletes of different nations had agreed to share the same medal in the history of Olympics. \n",
        "Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a \n",
        "'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and \n",
        "Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump\n",
        "for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg\n",
        "of Sweden (1984 to 1992).\n",
        "\n",
        "\n",
        "Second, we will **explicitly tell the model to make use of the provided context**. \n",
        "\n",
        "\n",
        "There's a deeper lesson here: **telling LLMs explicitly what you want them to do often helps** (kinda like parenting? 🤔)"
      ],
      "metadata": {
        "id": "Il-5WnlKFwip"
      },
      "id": "Il-5WnlKFwip"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fceaf665-2602-4788-bc44-9eb256a6f955",
      "metadata": {
        "id": "fceaf665-2602-4788-bc44-9eb256a6f955"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Answer the question as truthfully as possible using the \n",
        "provided text, and if the answer is not contained within the text below, \n",
        "say \"I don't know\"\n",
        "\n",
        "Context:\n",
        "The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium.\n",
        "33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places \n",
        "to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021).\n",
        "Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following\n",
        "a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance\n",
        "where the athletes of different nations had agreed to share the same medal in the history of Olympics. \n",
        "Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a \n",
        "'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and \n",
        "Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump\n",
        "for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg\n",
        "of Sweden (1984 to 1992).\n",
        "\n",
        "Q: Who won the 2020 Summer Olympics men's high jump?\n",
        "A:\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a moment to notice what the prompt has grown to.\n",
        "\n",
        "\n",
        "OK, let's run it."
      ],
      "metadata": {
        "id": "8KwCoDatGsFm"
      },
      "id": "8KwCoDatGsFm"
    },
    {
      "cell_type": "code",
      "source": [
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ],
      "metadata": {
        "id": "mfIYpFbg0tCI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "92df4c68-6746-4135-a815-07204d7d0597"
      },
      "id": "mfIYpFbg0tCI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Gianmarco Tamberi and Mutaz Essa Barshim emerged as joint winners of the event.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nicely done, `text-davinci-003`!\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "m4liRh5k04OA"
      },
      "id": "m4liRh5k04OA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "But maybe it wasn't super hard since the answer is literally in the context we provided.\n",
        "\n",
        "\n",
        "Let's make it a bit harder.\n",
        "\n",
        "\n",
        "Notice the last line in the context we provided.\n",
        ">Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg of Sweden (1984 to 1992).\n",
        "\n",
        "This tempts me to ask: Who is the **first** man to win three medals in high jump? \n",
        "\n",
        "Wicked, eh? 😸 \n",
        "\n",
        "Let's try it."
      ],
      "metadata": {
        "id": "Ru32ut0FJjMw"
      },
      "id": "Ru32ut0FJjMw"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the question as truthfully as possible using the \n",
        "provided text, and if the answer is not contained within the text below, \n",
        "say \"I don't know\"\n",
        "\n",
        "Context:\n",
        "The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium.\n",
        "33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places \n",
        "to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021).\n",
        "Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following\n",
        "a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance\n",
        "where the athletes of different nations had agreed to share the same medal in the history of Olympics. \n",
        "Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a \n",
        "'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and \n",
        "Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump\n",
        "for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg\n",
        "of Sweden (1984 to 1992).\n",
        "\n",
        "Q: Who is the first man to win three medals in high jump?\n",
        "A:\"\"\"\n"
      ],
      "metadata": {
        "id": "qpI9mMx5JSW5"
      },
      "id": "qpI9mMx5JSW5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the question has changed. Everything else is unchanged."
      ],
      "metadata": {
        "id": "M8gAZxH-KVhx"
      },
      "id": "M8gAZxH-KVhx"
    },
    {
      "cell_type": "code",
      "source": [
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ],
      "metadata": {
        "id": "vai7XuvCJe-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "eef9a93c-0f27-42d9-f649-a18523561585"
      },
      "id": "vai7XuvCJe-_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Patrik Sjöberg of Sweden.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHOAH!!!!\n",
        "\n",
        "👏 👍\n",
        "\n",
        "Not sure if a traditional search engine could have done that!\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "I7C-ejVqKcpU"
      },
      "id": "I7C-ejVqKcpU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automatically enriching the prompt with custom data"
      ],
      "metadata": {
        "id": "lsFc2fnWLHyK"
      },
      "id": "lsFc2fnWLHyK"
    },
    {
      "cell_type": "markdown",
      "id": "ee85ee77-d8d2-4788-b57e-0785f2d7e2e3",
      "metadata": {
        "id": "ee85ee77-d8d2-4788-b57e-0785f2d7e2e3"
      },
      "source": [
        "**Manually** adding extra information into the prompt obviously doesn't scale. So, we will now show how to **automatically** enrich the prompt with custom relevant data.\n",
        "\n",
        "First thing to note. We typically can't just include **all** the custom data into the prompt due to an important reason.\n",
        "\n",
        "The prompt for every model has a limit (called the **context window**) on how many tokens you can send in and get out. For `text-davinci-003`,  the context window is 4097 tokens ([link](https://help.openai.com/en/articles/6643408-how-do-davinci-and-text-davinci-003-differ)).\n",
        "\n",
        "Note that the context window includes both the prompt and the response - **together**, they can't exceed 4097 tokens. We will get deeper into this a bit later but for now, understand this is one key reason we can't include ALL data in the prompt. Another reason is expense. OpenAI charges by the token and these charges can easily add up.\n",
        "\n",
        "(BTW, GPT-4's context window is way bigger - it ranges from 8,192 to 32,768 tokens, depending on the particular GPT-4 model!)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we can't include all the custom data, the logical thing to do is to only include data that's **relevant** to the question.\n",
        "\n",
        "How can we measure the relevance between a question and a piece of (our custom) data?\n",
        "\n",
        "Using pretrained contextual embeddings!\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This is our overall process.\n",
        "\n"
      ],
      "metadata": {
        "id": "O2N4vj7pdaDh"
      },
      "id": "O2N4vj7pdaDh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-time setup**\n",
        "* Preprocess the custom dataset by splitting it into 'sections'\n",
        "* We calculate an embedding vector for each section using the `text-embedding-ada-002` model and store it somewhere handy\n",
        "\n",
        "\n",
        "**Each time we receive a question, we do this:**\n",
        "* We calculate an embedding vector for the question (again using the same `text-embedding-ada-002` model)\n",
        "* For each section in our custom dataset, we calculate the *cosine similarity* between that section's embedding vector and the question's embedding vector\n",
        "* We rank the sections from most-cosine-similar to the question to least-cosine-similar\n",
        "* Starting from the most-cosine-similar section, include as many sections into the prompt as can fit into the context window\n",
        "* Send the prompt into `text-davinci-003`."
      ],
      "metadata": {
        "id": "sEJbDq1EfHj3"
      },
      "id": "sEJbDq1EfHj3"
    },
    {
      "cell_type": "markdown",
      "id": "0c9bfea5-a028-4191-b9f1-f210d76ec4e3",
      "metadata": {
        "id": "0c9bfea5-a028-4191-b9f1-f210d76ec4e3"
      },
      "source": [
        "#### One-time setup\n",
        "\n",
        "We first need to break up the custom dataset into \"sections\".\n",
        "\n",
        "Sections should be large enough to contain enough information to answer a question; but small enough to fit one or several into the `text-davinci-003` prompt. \n",
        "\n",
        "Approximately a paragraph of text is usually a good length, but you should experiment for your particular use case. In this example, Wikipedia articles are already grouped into headers, so we will use these to define our sections. This preprocessing has already been done in [this notebook](https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-1-collect-data.ipynb), so we will load the results and use them. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9c8d69-e234-48b4-87e3-935970e1523a",
      "metadata": {
        "id": "cc9c8d69-e234-48b4-87e3-935970e1523a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "885f00a3-b198-4ad6-f197-958af775d273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3964 rows in the data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       content  \\\n",
              "title                                              heading                                                       \n",
              "Russian Olympic Committee athletes at the 2020 ... Road      ROC has entered a squad of four riders (three ...   \n",
              "Philippines at the 2020 Summer Olympics            Boxing    The Philippines entered four boxers (two per g...   \n",
              "Federated States of Micronesia at the 2020 Summ... Swimming  Federated States of Micronesia received a univ...   \n",
              "Honduras at the 2020 Summer Olympics               Summary   Honduras competed at the 2020 Summer Olympics ...   \n",
              "Yemen at the 2020 Summer Olympics                  Summary   Yemen competed at the 2020 Summer Olympics in ...   \n",
              "\n",
              "                                                             tokens  \n",
              "title                                              heading           \n",
              "Russian Olympic Committee athletes at the 2020 ... Road          57  \n",
              "Philippines at the 2020 Summer Olympics            Boxing       405  \n",
              "Federated States of Micronesia at the 2020 Summ... Swimming      55  \n",
              "Honduras at the 2020 Summer Olympics               Summary       64  \n",
              "Yemen at the 2020 Summer Olympics                  Summary       50  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7e88099-2578-4589-b981-33930f261aea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <th>heading</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Russian Olympic Committee athletes at the 2020 Summer Olympics</th>\n",
              "      <th>Road</th>\n",
              "      <td>ROC has entered a squad of four riders (three ...</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Philippines at the 2020 Summer Olympics</th>\n",
              "      <th>Boxing</th>\n",
              "      <td>The Philippines entered four boxers (two per g...</td>\n",
              "      <td>405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Federated States of Micronesia at the 2020 Summer Olympics</th>\n",
              "      <th>Swimming</th>\n",
              "      <td>Federated States of Micronesia received a univ...</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Honduras at the 2020 Summer Olympics</th>\n",
              "      <th>Summary</th>\n",
              "      <td>Honduras competed at the 2020 Summer Olympics ...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Yemen at the 2020 Summer Olympics</th>\n",
              "      <th>Summary</th>\n",
              "      <td>Yemen competed at the 2020 Summer Olympics in ...</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7e88099-2578-4589-b981-33930f261aea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7e88099-2578-4589-b981-33930f261aea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7e88099-2578-4589-b981-33930f261aea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# OpenAI has hosted the processed dataset, so we can download it directly without having to recreate it.\n",
        "# This dataset has already been split into sections, one row for each section of the Wikipedia page.\n",
        "\n",
        "df = pd.read_csv('https://cdn.openai.com/API/examples/data/olympics_sections_text.csv')\n",
        "df = df.set_index([\"title\", \"heading\"])\n",
        "print(f\"{len(df)} rows in the data.\")\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a17b88b9-7ea2-491e-9727-12617c74a77d",
      "metadata": {
        "id": "a17b88b9-7ea2-491e-9727-12617c74a77d"
      },
      "source": [
        "Next, we need to calculate an embedding vector for each section. \n",
        "\n",
        "Recall that an embedding is a vector of numbers that helps us understand how semantically similar or different the texts are. The closer two embeddings are to each other, the more similar are their contents. See the [documentation on OpenAI embeddings](https://beta.openai.com/docs/guides/embeddings) for more information.\n",
        "\n",
        "Since this is a small example, we can store the embeddings locally. If you have a larger dataset, consider using a vector search engine like [Pinecone](https://www.pinecone.io/) or [Weaviate](https://github.com/semi-technologies/weaviate)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculates the embedding using `text-embedding-ada-002`, given a piece of text. The API call is simple (see below). [Link](https://openai.com/blog/new-and-improved-embedding-model)."
      ],
      "metadata": {
        "id": "ygZKOYP6hFvO"
      },
      "id": "ygZKOYP6hFvO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba475f30-ef7f-431c-b60d-d5970b62ad09",
      "metadata": {
        "id": "ba475f30-ef7f-431c-b60d-d5970b62ad09"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
        "    result = openai.Embedding.create(\n",
        "      model=model,       # which embedding model we want to use\n",
        "      input=text         # feed in the text for which you want to calc the embedding\n",
        "    )\n",
        "    return result[\"data\"][0][\"embedding\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it on \"HODL is amazing!!\" 😃"
      ],
      "metadata": {
        "id": "Gm_jlpKEIY2f"
      },
      "id": "Gm_jlpKEIY2f"
    },
    {
      "cell_type": "code",
      "source": [
        "e = get_embedding(\"HODL is amazing!!\")"
      ],
      "metadata": {
        "id": "60l0L2BwIfd4"
      },
      "id": "60l0L2BwIfd4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e"
      ],
      "metadata": {
        "id": "IuSh7vvE2unm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec55f45d-a2e3-4774-9614-a713881028c8"
      },
      "id": "IuSh7vvE2unm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.007875289767980576,\n",
              " 0.0033526234328746796,\n",
              " -0.009611068293452263,\n",
              " -0.027181001380085945,\n",
              " -0.022436540573835373,\n",
              " -0.001679526176303625,\n",
              " -0.008299591019749641,\n",
              " 0.006573456339538097,\n",
              " 0.006730962079018354,\n",
              " -0.032092608511447906,\n",
              " 0.007020258344709873,\n",
              " 0.01144327875226736,\n",
              " -0.007624566555023193,\n",
              " 0.0029074284248054028,\n",
              " 0.014876262284815311,\n",
              " 0.010343952104449272,\n",
              " 0.01805209368467331,\n",
              " 0.01083897054195404,\n",
              " 0.019312139600515366,\n",
              " -0.0018306031124666333,\n",
              " -0.029572516679763794,\n",
              " 0.0028479620814323425,\n",
              " -0.037929967045784,\n",
              " 0.006258444860577583,\n",
              " -0.019775014370679855,\n",
              " -0.005548061337321997,\n",
              " 0.020816480740904808,\n",
              " -0.01360335759818554,\n",
              " 0.009591781534254551,\n",
              " -0.03808426111936569,\n",
              " 0.009553208947181702,\n",
              " -0.008948900736868382,\n",
              " -0.02529093064367771,\n",
              " -0.006724533159285784,\n",
              " -0.019427858293056488,\n",
              " -0.009257483296096325,\n",
              " -0.01832210272550583,\n",
              " 0.005342339631170034,\n",
              " 0.0001882435317384079,\n",
              " 0.00999679695814848,\n",
              " 0.026692410930991173,\n",
              " -0.01148828025907278,\n",
              " -0.001528449123725295,\n",
              " 0.0023143708240240812,\n",
              " -0.029238220304250717,\n",
              " 0.003709422191604972,\n",
              " 0.0036226334050297737,\n",
              " -0.013821937143802643,\n",
              " -0.0007232408970594406,\n",
              " -0.0012825472513213754,\n",
              " 0.008621031418442726,\n",
              " 0.011809720657765865,\n",
              " 0.006775963585823774,\n",
              " -0.012806185521185398,\n",
              " 0.006277731154114008,\n",
              " 0.02019931562244892,\n",
              " 0.006795250345021486,\n",
              " 0.013590500690042973,\n",
              " 0.016534894704818726,\n",
              " -0.031809743493795395,\n",
              " 0.011835435405373573,\n",
              " -0.012336882762610912,\n",
              " -0.0214979350566864,\n",
              " 0.03677278384566307,\n",
              " 0.006737390998750925,\n",
              " -0.029495371505618095,\n",
              " 0.0031517231836915016,\n",
              " -0.004419805482029915,\n",
              " -0.0020620401483029127,\n",
              " 0.02156222239136696,\n",
              " 0.012484745122492313,\n",
              " 0.02009645476937294,\n",
              " -0.007971721701323986,\n",
              " -0.00289135635830462,\n",
              " 0.003227261593565345,\n",
              " -0.00650595361366868,\n",
              " -0.027541013434529305,\n",
              " 0.011636142618954182,\n",
              " 0.010112515650689602,\n",
              " 0.00705883139744401,\n",
              " 0.017332065850496292,\n",
              " -0.02205081097781658,\n",
              " 0.013770506717264652,\n",
              " 0.01148828025907278,\n",
              " 0.00870460644364357,\n",
              " -0.00676310621201992,\n",
              " -0.015969159081578255,\n",
              " 0.017627792432904243,\n",
              " -0.014181951060891151,\n",
              " -0.020430753007531166,\n",
              " 0.02980395406484604,\n",
              " -0.018463537096977234,\n",
              " 0.0020202528685331345,\n",
              " 0.000332891708239913,\n",
              " -0.020057881250977516,\n",
              " 0.032401192933321,\n",
              " 0.0009811968775466084,\n",
              " 0.024146603420376778,\n",
              " -0.013320490717887878,\n",
              " -0.012324024923145771,\n",
              " -0.0005408235010690987,\n",
              " 0.00467374362051487,\n",
              " -0.004596597980707884,\n",
              " -0.011610427871346474,\n",
              " -0.019672153517603874,\n",
              " -0.01069110818207264,\n",
              " 0.01906784437596798,\n",
              " 0.016226312145590782,\n",
              " -0.012561891227960587,\n",
              " -0.014760543592274189,\n",
              " 0.00680167879909277,\n",
              " 0.001094504608772695,\n",
              " -0.011835435405373573,\n",
              " -0.0483703538775444,\n",
              " 0.01218259148299694,\n",
              " 0.010916116647422314,\n",
              " -0.008833182044327259,\n",
              " 0.0012415635865181684,\n",
              " 0.010408240370452404,\n",
              " -0.016972053796052933,\n",
              " 0.011893294751644135,\n",
              " 0.012471888214349747,\n",
              " 0.018270673230290413,\n",
              " -0.0059723625890910625,\n",
              " -0.006923826411366463,\n",
              " -0.004464807454496622,\n",
              " -0.03214403986930847,\n",
              " -0.015326278284192085,\n",
              " 0.01560914609581232,\n",
              " -0.0031051142141222954,\n",
              " 0.029289649799466133,\n",
              " 0.024236606433987617,\n",
              " -0.011809720657765865,\n",
              " -0.01621345430612564,\n",
              " -0.002770816208794713,\n",
              " 0.02046932466328144,\n",
              " -0.015956301242113113,\n",
              " -0.014734827913343906,\n",
              " 0.004901966080069542,\n",
              " 0.0015220203204080462,\n",
              " 0.019942162558436394,\n",
              " 0.028029603883624077,\n",
              " 0.010421098209917545,\n",
              " -0.0073481276631355286,\n",
              " -0.030395405367016792,\n",
              " 0.009739643894135952,\n",
              " 0.014979123137891293,\n",
              " 0.01566057652235031,\n",
              " 0.0006380592240020633,\n",
              " -0.0010607533622533083,\n",
              " 0.019196420907974243,\n",
              " -0.021356500685214996,\n",
              " 0.009514636360108852,\n",
              " 0.01008679997175932,\n",
              " -0.00024047760234680027,\n",
              " 0.006936683785170317,\n",
              " 0.021227924153208733,\n",
              " -0.005879145115613937,\n",
              " 0.0017598862759768963,\n",
              " -0.007875289767980576,\n",
              " -0.013044051826000214,\n",
              " -0.015403424389660358,\n",
              " 0.004291229415684938,\n",
              " 0.014413387514650822,\n",
              " 0.004313730169087648,\n",
              " 0.014734827913343906,\n",
              " 0.029521087184548378,\n",
              " -0.00186435435898602,\n",
              " 0.0029620733112096786,\n",
              " 0.003805854357779026,\n",
              " -0.005258765071630478,\n",
              " 0.02823532558977604,\n",
              " -0.03232404589653015,\n",
              " 0.01702348329126835,\n",
              " -0.024969490244984627,\n",
              " 0.030909709632396698,\n",
              " 0.011250413954257965,\n",
              " 0.011423991993069649,\n",
              " -0.026319541037082672,\n",
              " -0.01591772958636284,\n",
              " 0.008614602498710155,\n",
              " 0.01611059345304966,\n",
              " 0.013539070263504982,\n",
              " 0.025972384959459305,\n",
              " -0.015531999990344048,\n",
              " 0.0012270987499505281,\n",
              " 0.018849264830350876,\n",
              " -0.016702042892575264,\n",
              " 0.016136309131979942,\n",
              " -8.407675341004506e-05,\n",
              " -0.011417563073337078,\n",
              " 0.007926720194518566,\n",
              " -0.002108649117872119,\n",
              " 0.0021006129682064056,\n",
              " -0.6430865526199341,\n",
              " -0.0243394672870636,\n",
              " 0.00010657758684828877,\n",
              " 0.008871755562722683,\n",
              " 0.006988114211708307,\n",
              " -0.002156865084543824,\n",
              " 0.015814868733286858,\n",
              " 0.00675667729228735,\n",
              " -0.009276770055294037,\n",
              " 0.013089053332805634,\n",
              " 0.021253639832139015,\n",
              " 0.024120887741446495,\n",
              " -0.01555771566927433,\n",
              " -0.0026583122089505196,\n",
              " -0.003931215964257717,\n",
              " -0.023928023874759674,\n",
              " -0.000927355547901243,\n",
              " -0.04626170173287392,\n",
              " -0.009887507185339928,\n",
              " -0.01684347726404667,\n",
              " -0.0018386391457170248,\n",
              " 0.02759244479238987,\n",
              " -0.014053374528884888,\n",
              " -0.0077274274080991745,\n",
              " 0.0028479620814323425,\n",
              " -0.004551596008241177,\n",
              " 0.009900364093482494,\n",
              " -0.007270982023328543,\n",
              " -0.018939267843961716,\n",
              " 0.03029254451394081,\n",
              " 0.006602386012673378,\n",
              " 0.0058148568496108055,\n",
              " -0.00400836206972599,\n",
              " 0.014104804955422878,\n",
              " 0.051816195249557495,\n",
              " -0.02139507420361042,\n",
              " -0.012285452336072922,\n",
              " 0.033378370106220245,\n",
              " -0.01407909020781517,\n",
              " 0.04639028012752533,\n",
              " -0.02369658648967743,\n",
              " -0.015853440389037132,\n",
              " 0.007438131142407656,\n",
              " -0.009977510198950768,\n",
              " -0.009617497213184834,\n",
              " 0.015699150040745735,\n",
              " 0.012420456856489182,\n",
              " -0.008273876272141933,\n",
              " -0.01290904637426138,\n",
              " -0.013410493731498718,\n",
              " -0.005895216949284077,\n",
              " -0.005377698224037886,\n",
              " -0.017434928566217422,\n",
              " 0.005004826933145523,\n",
              " -0.02676955796778202,\n",
              " -0.015441996976733208,\n",
              " 0.026036672294139862,\n",
              " 0.004728388506919146,\n",
              " -0.003709422191604972,\n",
              " -0.0019286423921585083,\n",
              " 0.006769535131752491,\n",
              " 0.024223748594522476,\n",
              " -0.02100934460759163,\n",
              " -0.03260691463947296,\n",
              " -0.014734827913343906,\n",
              " 0.01694633811712265,\n",
              " -0.016522036865353584,\n",
              " 0.0054548438638448715,\n",
              " 0.006563812959939241,\n",
              " -0.018656400963664055,\n",
              " -5.499644612427801e-05,\n",
              " 0.01407909020781517,\n",
              " -0.007598851341754198,\n",
              " -0.013166199438273907,\n",
              " 0.014001944102346897,\n",
              " 0.007007400970906019,\n",
              " 0.028003888204693794,\n",
              " -0.007553849369287491,\n",
              " 0.02390230819582939,\n",
              " 0.04705887660384178,\n",
              " -0.0007493579760193825,\n",
              " -0.02148507721722126,\n",
              " -0.03276120498776436,\n",
              " -0.020996486768126488,\n",
              " 0.02787531167268753,\n",
              " 0.006055937148630619,\n",
              " -0.0075024189427495,\n",
              " -0.009977510198950768,\n",
              " 0.0008397630881518126,\n",
              " 0.0035487019922584295,\n",
              " 0.007843146100640297,\n",
              " 0.01870783232152462,\n",
              " 0.03029254451394081,\n",
              " -0.03610418736934662,\n",
              " 0.0040565780363976955,\n",
              " 0.03841855749487877,\n",
              " 0.013037622906267643,\n",
              " 0.018926411867141724,\n",
              " 0.005528775043785572,\n",
              " -0.021870804950594902,\n",
              " 0.005062686279416084,\n",
              " -0.007123119197785854,\n",
              " 0.001972036901861429,\n",
              " 0.031706880778074265,\n",
              " -0.00390228652395308,\n",
              " 0.013924797996878624,\n",
              " -0.0023079421371221542,\n",
              " 0.02990681491792202,\n",
              " 0.018952125683426857,\n",
              " -0.0230665635317564,\n",
              " 0.01721634902060032,\n",
              " 0.012516889721155167,\n",
              " -0.0003797014942392707,\n",
              " -0.0053005521185696125,\n",
              " -0.02565094456076622,\n",
              " -0.035795602947473526,\n",
              " 0.01213116105645895,\n",
              " 0.006142726168036461,\n",
              " 0.012696895748376846,\n",
              " -0.014979123137891293,\n",
              " 0.028775345534086227,\n",
              " -0.011906152591109276,\n",
              " 0.0020347177051007748,\n",
              " 0.013281917199492455,\n",
              " -0.01477340143173933,\n",
              " -0.008865326642990112,\n",
              " 0.0008952115313149989,\n",
              " -0.03484414145350456,\n",
              " -0.012651894241571426,\n",
              " 0.0042269411496818066,\n",
              " -0.001702026929706335,\n",
              " -0.013847652822732925,\n",
              " 0.008678890764713287,\n",
              " -0.011546139605343342,\n",
              " 0.015184844844043255,\n",
              " 0.005753783509135246,\n",
              " -0.011784004978835583,\n",
              " -0.0192607082426548,\n",
              " 0.010716822929680347,\n",
              " -0.03258119896054268,\n",
              " 0.0025988456327468157,\n",
              " 0.013114769011735916,\n",
              " 0.010543244890868664,\n",
              " -0.01467054057866335,\n",
              " -0.02174222841858864,\n",
              " -0.04101579636335373,\n",
              " 0.010511101223528385,\n",
              " 0.006750248372554779,\n",
              " 0.030781133100390434,\n",
              " -0.024043742567300797,\n",
              " -0.003047255100682378,\n",
              " 0.002460626419633627,\n",
              " 0.0001972840545931831,\n",
              " 0.01486340444535017,\n",
              " -0.0007694480009377003,\n",
              " 0.008582458831369877,\n",
              " 0.0032369049731642008,\n",
              " 0.021227924153208733,\n",
              " -0.007508847862482071,\n",
              " -0.009167480282485485,\n",
              " -0.017396355047822,\n",
              " 0.004901966080069542,\n",
              " -0.010530387982726097,\n",
              " -0.021690798923373222,\n",
              " -0.02174222841858864,\n",
              " -0.020803622901439667,\n",
              " -0.007585993502289057,\n",
              " 0.04006433114409447,\n",
              " 0.01347478199750185,\n",
              " -0.025252358987927437,\n",
              " -0.0015067518688738346,\n",
              " 0.006563812959939241,\n",
              " -0.03147544339299202,\n",
              " 0.017074914649128914,\n",
              " 0.0018081022426486015,\n",
              " 0.004432663321495056,\n",
              " -0.0022404396440833807,\n",
              " -0.03785282373428345,\n",
              " -4.500165596255101e-05,\n",
              " 0.012581177055835724,\n",
              " 0.02592095360159874,\n",
              " -0.017704937607049942,\n",
              " -0.019042130559682846,\n",
              " 0.002315978053957224,\n",
              " 0.033301226794719696,\n",
              " 0.00824173167347908,\n",
              " -0.013410493731498718,\n",
              " 0.03443269804120064,\n",
              " 0.015570573508739471,\n",
              " 0.004834463819861412,\n",
              " 0.015094841830432415,\n",
              " 0.03592418134212494,\n",
              " 0.020687904208898544,\n",
              " -0.0035101291723549366,\n",
              " -0.01338477898389101,\n",
              " -0.012375455349683762,\n",
              " -0.009739643894135952,\n",
              " 0.0027997458819299936,\n",
              " 0.01751207374036312,\n",
              " 0.03132115304470062,\n",
              " 0.015017695724964142,\n",
              " -0.011288987472653389,\n",
              " -0.007669568061828613,\n",
              " 0.0070009720511734486,\n",
              " -0.014451961033046246,\n",
              " -0.00795886479318142,\n",
              " 0.0073802717961370945,\n",
              " -0.01338477898389101,\n",
              " -0.0008301198249682784,\n",
              " 0.0014906799187883735,\n",
              " -0.0046255276538431644,\n",
              " -0.007142405956983566,\n",
              " -0.0036451341584324837,\n",
              " 0.0162005964666605,\n",
              " -0.016406318172812462,\n",
              " 0.04631313309073448,\n",
              " 0.01648346334695816,\n",
              " -0.008511741645634174,\n",
              " -0.009546780027449131,\n",
              " -0.010755396448075771,\n",
              " -0.005615564063191414,\n",
              " -0.014966265298426151,\n",
              " 0.0020781122148036957,\n",
              " -0.01347478199750185,\n",
              " 0.018219241872429848,\n",
              " 0.002054004231467843,\n",
              " 0.017293494194746017,\n",
              " 0.014451961033046246,\n",
              " -0.01702348329126835,\n",
              " 0.010369667783379555,\n",
              " -0.029109643772244453,\n",
              " 0.01760207675397396,\n",
              " 0.004686600994318724,\n",
              " -0.009270341135561466,\n",
              " 0.0018016734393313527,\n",
              " 0.014554821886122227,\n",
              " 0.03247833997011185,\n",
              " -0.015133414417505264,\n",
              " 0.041144371032714844,\n",
              " -0.002737065078690648,\n",
              " -0.004577311221510172,\n",
              " 0.013005479238927364,\n",
              " 0.014323384501039982,\n",
              " -0.011166839860379696,\n",
              " -0.007688854355365038,\n",
              " 0.013127625919878483,\n",
              " 0.029469655826687813,\n",
              " 0.0014513034839183092,\n",
              " 0.0063388049602508545,\n",
              " -0.006538097746670246,\n",
              " -0.0025458079762756824,\n",
              " -0.004946968052536249,\n",
              " 0.002369015710428357,\n",
              " -0.015313421376049519,\n",
              " 0.0070459735579788685,\n",
              " -0.008318877778947353,\n",
              " 0.01935071311891079,\n",
              " 0.01495340745896101,\n",
              " 0.022449398413300514,\n",
              " 0.014644824899733067,\n",
              " 0.03651563078165054,\n",
              " 0.018630685284733772,\n",
              " 0.00323047605343163,\n",
              " -0.012696895748376846,\n",
              " -0.006297017447650433,\n",
              " 0.0020507897716015577,\n",
              " -0.005917717702686787,\n",
              " 0.008531028404831886,\n",
              " 0.0011933475034311414,\n",
              " 0.017717795446515083,\n",
              " 0.007765999995172024,\n",
              " -0.02054647170007229,\n",
              " -0.014850546605885029,\n",
              " -0.008691748604178429,\n",
              " 0.014747685752809048,\n",
              " 0.007206693757325411,\n",
              " -0.0005203316686674953,\n",
              " 0.015982016921043396,\n",
              " -0.030858278274536133,\n",
              " 0.005515917204320431,\n",
              " -0.013783364556729794,\n",
              " -0.023863736540079117,\n",
              " 0.03193831816315651,\n",
              " 0.013834794983267784,\n",
              " 0.00117004313506186,\n",
              " -0.024493759498000145,\n",
              " -0.018167812377214432,\n",
              " -0.01915784738957882,\n",
              " -0.0107489675283432,\n",
              " 0.03121829219162464,\n",
              " 0.012516889721155167,\n",
              " -0.012934762053191662,\n",
              " -0.019093560054898262,\n",
              " 0.0029251077212393284,\n",
              " 0.005171976052224636,\n",
              " -0.014271954074501991,\n",
              " 0.04497594013810158,\n",
              " 0.00539698451757431,\n",
              " 0.0038572847843170166,\n",
              " -0.008569600991904736,\n",
              " 0.00437158951535821,\n",
              " 0.0031469014938920736,\n",
              " -0.02741243876516819,\n",
              " -0.03129543736577034,\n",
              " 0.008820325136184692,\n",
              " 0.0015517536085098982,\n",
              " 0.008717464283108711,\n",
              " -0.020765049383044243,\n",
              " 0.0011097730603069067,\n",
              " 0.00017217152344528586,\n",
              " 0.02658955007791519,\n",
              " -0.03535844385623932,\n",
              " -0.012484745122492313,\n",
              " -0.01860497146844864,\n",
              " 0.006724533159285784,\n",
              " 0.010511101223528385,\n",
              " -0.020327892154455185,\n",
              " -0.005069115199148655,\n",
              " 0.04513023421168327,\n",
              " 0.01639346033334732,\n",
              " -0.02174222841858864,\n",
              " 0.00444552069529891,\n",
              " -0.02084219641983509,\n",
              " 0.00405336357653141,\n",
              " 0.10270664095878601,\n",
              " -0.012838330119848251,\n",
              " 0.004844106733798981,\n",
              " 0.004194797482341528,\n",
              " 0.00046006159391254187,\n",
              " 0.0068338229320943356,\n",
              " 0.006226300727576017,\n",
              " -0.02620382234454155,\n",
              " -0.006898111198097467,\n",
              " -5.035062713432126e-05,\n",
              " -0.00612986832857132,\n",
              " -0.03173259645700455,\n",
              " -0.0003019530849996954,\n",
              " 0.004271943122148514,\n",
              " -0.0015035375254228711,\n",
              " -0.014091947115957737,\n",
              " -0.003551916452124715,\n",
              " 0.0012431708164513111,\n",
              " 0.011141124181449413,\n",
              " 0.009180338121950626,\n",
              " 0.004721959587186575,\n",
              " 0.021716514602303505,\n",
              " -0.0014681790489703417,\n",
              " 0.029186788946390152,\n",
              " 0.027103854343295097,\n",
              " -0.011218270286917686,\n",
              " 0.023580867797136307,\n",
              " 0.007322412449866533,\n",
              " 0.009013189002871513,\n",
              " 0.00676310621201992,\n",
              " -0.005953076295554638,\n",
              " -0.013744791969656944,\n",
              " -0.016907764598727226,\n",
              " 0.016792047768831253,\n",
              " 0.0046255276538431644,\n",
              " -0.003551916452124715,\n",
              " -0.013371921144425869,\n",
              " -0.015351993963122368,\n",
              " 0.007483132649213076,\n",
              " -0.018489252775907516,\n",
              " 0.019376426935195923,\n",
              " 0.01962072215974331,\n",
              " 0.0030906496103852987,\n",
              " 0.004397304728627205,\n",
              " -0.009476062841713428,\n",
              " -0.004831249359995127,\n",
              " -0.005261979531496763,\n",
              " 0.0346384197473526,\n",
              " -0.02073933556675911,\n",
              " -0.007084546610713005,\n",
              " 0.0037383518647402525,\n",
              " 0.017640650272369385,\n",
              " -0.014220523647964,\n",
              " 0.00636452017351985,\n",
              " 0.002467055106535554,\n",
              " 0.0036901358980685472,\n",
              " -0.02027646079659462,\n",
              " -0.018219241872429848,\n",
              " -0.012201878242194653,\n",
              " -0.03664420545101166,\n",
              " -0.0401671938598156,\n",
              " -0.033661238849163055,\n",
              " 0.009386059828102589,\n",
              " -0.009206052869558334,\n",
              " -0.004095150623470545,\n",
              " -0.03247833997011185,\n",
              " -0.024018026888370514,\n",
              " -0.02887820638716221,\n",
              " -0.011803291738033295,\n",
              " -0.003931215964257717,\n",
              " 0.001918999245390296,\n",
              " 0.008916757069528103,\n",
              " -0.030395405367016792,\n",
              " -0.002304727677255869,\n",
              " 0.027566729113459587,\n",
              " 0.015866298228502274,\n",
              " -0.020957915112376213,\n",
              " 0.019685011357069016,\n",
              " 0.002663133665919304,\n",
              " 0.024300895631313324,\n",
              " 0.009379630908370018,\n",
              " 0.007997437380254269,\n",
              " -0.008203159086406231,\n",
              " -0.005965934135019779,\n",
              " 0.0012423672014847398,\n",
              " 0.0008176640258170664,\n",
              " -0.0024204463697969913,\n",
              " -0.0047830333933234215,\n",
              " 0.020147884264588356,\n",
              " 0.026088103652000427,\n",
              " 0.02103506028652191,\n",
              " 0.004230155609548092,\n",
              " 0.030986854806542397,\n",
              " -0.015184844844043255,\n",
              " -0.007888147607445717,\n",
              " -0.023298000916838646,\n",
              " 0.017293494194746017,\n",
              " 0.009424632415175438,\n",
              " 0.00028467565425671637,\n",
              " 0.0068338229320943356,\n",
              " 0.00606236606836319,\n",
              " -0.002092577051371336,\n",
              " -0.017820656299591064,\n",
              " 0.0061716558411717415,\n",
              " 0.01584058254957199,\n",
              " -0.008479597978293896,\n",
              " -0.01842496357858181,\n",
              " -0.00710383290424943,\n",
              " -0.02370944432914257,\n",
              " 0.0033494089730083942,\n",
              " -0.010941831395030022,\n",
              " -0.026332398876547813,\n",
              " -0.027541013434529305,\n",
              " -0.016162022948265076,\n",
              " -0.0056573511101305485,\n",
              " 0.004612669814378023,\n",
              " 0.0024590191897004843,\n",
              " 0.012754755094647408,\n",
              " -0.02482805773615837,\n",
              " -0.007283839397132397,\n",
              " -0.02035360597074032,\n",
              " 0.002759565832093358,\n",
              " 0.021960807964205742,\n",
              " 0.0008381558582186699,\n",
              " 0.009476062841713428,\n",
              " 0.002298298990353942,\n",
              " 0.009784646332263947,\n",
              " -0.02121506631374359,\n",
              " -0.003995504230260849,\n",
              " 0.011777576059103012,\n",
              " -0.005763426423072815,\n",
              " 0.025046637281775475,\n",
              " -0.02880106121301651,\n",
              " -0.007746713701635599,\n",
              " -0.017293494194746017,\n",
              " -0.008408880792558193,\n",
              " -0.029495371505618095,\n",
              " -0.01490197703242302,\n",
              " -0.025226643308997154,\n",
              " -0.019582148641347885,\n",
              " -0.03278692066669464,\n",
              " -0.04502737149596214,\n",
              " 0.022757980972528458,\n",
              " -0.021266497671604156,\n",
              " -0.04626170173287392,\n",
              " -0.024030884727835655,\n",
              " -0.005756997503340244,\n",
              " 0.00201543141156435,\n",
              " -0.008473169058561325,\n",
              " 0.018939267843961716,\n",
              " 0.005531989503651857,\n",
              " 0.009013189002871513,\n",
              " -0.008672461844980717,\n",
              " 0.011417563073337078,\n",
              " 0.009546780027449131,\n",
              " -0.01657346822321415,\n",
              " 0.004786247853189707,\n",
              " -0.010581818409264088,\n",
              " 0.01203472912311554,\n",
              " 0.02269369177520275,\n",
              " 0.04183868318796158,\n",
              " 0.01852782443165779,\n",
              " 0.04070721194148064,\n",
              " 0.0027788523584604263,\n",
              " 0.004779818933457136,\n",
              " -0.009238197468221188,\n",
              " 0.00606879498809576,\n",
              " -0.015236275270581245,\n",
              " -0.03471556305885315,\n",
              " 0.014220523647964,\n",
              " 0.01551914308220148,\n",
              " 0.000292510783765465,\n",
              " 0.01684347726404667,\n",
              " -0.021999381482601166,\n",
              " -0.009816789999604225,\n",
              " -0.01079396903514862,\n",
              " -0.004959825426340103,\n",
              " -0.02361944131553173,\n",
              " -0.017936374992132187,\n",
              " 0.0042783720418810844,\n",
              " -0.014284811913967133,\n",
              " 0.0018338175723329186,\n",
              " -0.007097403984516859,\n",
              " 0.003089042380452156,\n",
              " -0.03147544339299202,\n",
              " -0.019234994426369667,\n",
              " 0.011333988979458809,\n",
              " 0.004535524174571037,\n",
              " 0.023645156994462013,\n",
              " -0.0006219872157089412,\n",
              " 0.02529093064367771,\n",
              " -0.007078117690980434,\n",
              " -0.00874960795044899,\n",
              " 0.013397635892033577,\n",
              " 0.02611381933093071,\n",
              " 0.007933149114251137,\n",
              " 0.016046304255723953,\n",
              " -0.018450679257512093,\n",
              " 0.0008518170798197389,\n",
              " 0.02982966974377632,\n",
              " 0.0019913234282284975,\n",
              " 0.027283862233161926,\n",
              " 0.006898111198097467,\n",
              " 0.011668287217617035,\n",
              " -0.010916116647422314,\n",
              " 0.009096763096749783,\n",
              " -0.022102242335677147,\n",
              " 0.014413387514650822,\n",
              " 0.003789782291278243,\n",
              " -0.04271300137042999,\n",
              " 0.005181619431823492,\n",
              " -0.023452291265130043,\n",
              " -0.005596277303993702,\n",
              " -0.012613321654498577,\n",
              " 0.011263271793723106,\n",
              " 0.013281917199492455,\n",
              " 0.0017084557330235839,\n",
              " 0.005483773536980152,\n",
              " 0.008678890764713287,\n",
              " -0.00020542051061056554,\n",
              " 0.004333016462624073,\n",
              " 0.013095482252538204,\n",
              " 0.03944716602563858,\n",
              " -0.0036676351446658373,\n",
              " 0.012536175549030304,\n",
              " 0.025689518079161644,\n",
              " -0.005885574035346508,\n",
              " -0.011886865831911564,\n",
              " 0.00874317903071642,\n",
              " 0.0013789793010801077,\n",
              " 0.020610759034752846,\n",
              " 0.01953071914613247,\n",
              " 0.0016208632150664926,\n",
              " 0.010543244890868664,\n",
              " -0.033095505088567734,\n",
              " -0.0004733210080303252,\n",
              " 0.01287047378718853,\n",
              " -0.005210549104958773,\n",
              " -0.02565094456076622,\n",
              " 0.025805236771702766,\n",
              " 0.004731602966785431,\n",
              " 0.023285143077373505,\n",
              " -0.002092577051371336,\n",
              " -0.007624566555023193,\n",
              " 0.0005934593500569463,\n",
              " -0.019234994426369667,\n",
              " -0.0059820059686899185,\n",
              " 0.007856003940105438,\n",
              " -0.010703965090215206,\n",
              " -0.004390875808894634,\n",
              " -0.016804903745651245,\n",
              " -0.0016417568549513817,\n",
              " -0.018296387046575546,\n",
              " 0.001599166076630354,\n",
              " -0.025136640295386314,\n",
              " 0.014233381487429142,\n",
              " -0.004493736661970615,\n",
              " -0.021189352497458458,\n",
              " 0.01064610667526722,\n",
              " 0.008473169058561325,\n",
              " -0.0023995526134967804,\n",
              " 0.03425268828868866,\n",
              " -0.02203795500099659,\n",
              " -0.02619096450507641,\n",
              " 0.02520092763006687,\n",
              " -0.005599491763859987,\n",
              " -0.010363238863646984,\n",
              " -0.016072019934654236,\n",
              " -0.008453882299363613,\n",
              " 0.014156235381960869,\n",
              " -0.018669258803129196,\n",
              " -0.034021250903606415,\n",
              " 0.005904860328882933,\n",
              " -0.006065580528229475,\n",
              " -0.0063388049602508545,\n",
              " -0.026795271784067154,\n",
              " -0.03232404589653015,\n",
              " -0.02093219943344593,\n",
              " -0.018772119656205177,\n",
              " 0.007630995474755764,\n",
              " 0.004731602966785431,\n",
              " -0.011983298696577549,\n",
              " 0.016059162095189095,\n",
              " -0.0038187119644135237,\n",
              " -0.002423660596832633,\n",
              " 0.00714883441105485,\n",
              " -0.010305379517376423,\n",
              " -0.011655429378151894,\n",
              " 0.024789484217762947,\n",
              " -0.025599513202905655,\n",
              " -0.03705564886331558,\n",
              " -0.020585043355822563,\n",
              " 0.02073933556675911,\n",
              " 0.012111874297261238,\n",
              " 0.01742207072675228,\n",
              " 0.0017052413895726204,\n",
              " 0.011006119661033154,\n",
              " 0.035589881241321564,\n",
              " -0.002937965327873826,\n",
              " 0.0246351920068264,\n",
              " 0.01342335157096386,\n",
              " 0.014837688766419888,\n",
              " -0.0013805865310132504,\n",
              " -0.0053326962515711784,\n",
              " 0.003047255100682378,\n",
              " -0.021317927166819572,\n",
              " 0.0006898914580233395,\n",
              " -0.002487948862835765,\n",
              " -0.0017068485030904412,\n",
              " -0.01785922981798649,\n",
              " 0.00270974263548851,\n",
              " 0.0017791726859286427,\n",
              " 0.0109739750623703,\n",
              " -0.009321771562099457,\n",
              " 0.016534894704818726,\n",
              " 0.009623926132917404,\n",
              " 0.006743819918483496,\n",
              " -0.02648668922483921,\n",
              " -0.03417554497718811,\n",
              " 0.02972680889070034,\n",
              " -0.019234994426369667,\n",
              " 0.008820325136184692,\n",
              " 0.011591141112148762,\n",
              " -0.017344923689961433,\n",
              " 0.0009386059828102589,\n",
              " 0.008434596471488476,\n",
              " -0.007020258344709873,\n",
              " -0.02223081886768341,\n",
              " -0.023310858756303787,\n",
              " 0.006412736140191555,\n",
              " 2.2993660877546063e-06,\n",
              " -0.010806826874613762,\n",
              " -0.009463205933570862,\n",
              " -0.0127290403470397,\n",
              " -0.008910328149795532,\n",
              " -0.013269060291349888,\n",
              " -0.001084861345589161,\n",
              " 0.015904871746897697,\n",
              " -0.01963357999920845,\n",
              " -0.011192554607987404,\n",
              " 0.016136309131979942,\n",
              " 0.0470331609249115,\n",
              " 0.009116049855947495,\n",
              " -0.007984579540789127,\n",
              " -0.0016618468798696995,\n",
              " -0.007438131142407656,\n",
              " 0.010999690741300583,\n",
              " -0.010896829888224602,\n",
              " -0.02176794409751892,\n",
              " -0.013873367570340633,\n",
              " -0.01157828327268362,\n",
              " 0.022822268307209015,\n",
              " 0.011751861311495304,\n",
              " -0.022333679720759392,\n",
              " -0.013217629864811897,\n",
              " 0.037544239312410355,\n",
              " -0.02684670314192772,\n",
              " 0.0025072351563721895,\n",
              " -0.024313751608133316,\n",
              " -0.001485054730437696,\n",
              " 0.037261370569467545,\n",
              " 0.002844747621566057,\n",
              " 0.015712007880210876,\n",
              " 0.03651563078165054,\n",
              " 0.018090665340423584,\n",
              " 0.027721021324396133,\n",
              " -0.009836076758801937,\n",
              " 0.01005465630441904,\n",
              " 0.01591772958636284,\n",
              " -0.02305370569229126,\n",
              " 0.008363879285752773,\n",
              " -0.0071809785440564156,\n",
              " -0.050221849232912064,\n",
              " 0.0036612062249332666,\n",
              " 0.025162354111671448,\n",
              " 0.021626509726047516,\n",
              " 0.022847983986139297,\n",
              " 0.024326609447598457,\n",
              " -0.008177444338798523,\n",
              " 0.004005147609859705,\n",
              " -0.015197702683508396,\n",
              " 0.012195449322462082,\n",
              " 0.006335590500384569,\n",
              " 0.02341371960937977,\n",
              " -0.02066218852996826,\n",
              " -0.026280967518687248,\n",
              " 0.008132441900670528,\n",
              " -0.0007485543610528111,\n",
              " 0.017473500221967697,\n",
              " 0.009501778520643711,\n",
              " 0.011642571538686752,\n",
              " 0.014747685752809048,\n",
              " 0.005480559077113867,\n",
              " -0.029109643772244453,\n",
              " -0.03147544339299202,\n",
              " -0.016534894704818726,\n",
              " 0.007097403984516859,\n",
              " -0.008614602498710155,\n",
              " -0.009386059828102589,\n",
              " -0.006255230400711298,\n",
              " -0.028003888204693794,\n",
              " 0.02982966974377632,\n",
              " 0.011012548580765724,\n",
              " -0.002423660596832633,\n",
              " 0.011861151084303856,\n",
              " -0.009810361079871655,\n",
              " -0.012664752081036568,\n",
              " -0.03381552919745445,\n",
              " -0.01356478501111269,\n",
              " -0.03517843782901764,\n",
              " 0.008621031418442726,\n",
              " -0.021986523643136024,\n",
              " 0.021137921139597893,\n",
              " -0.020392179489135742,\n",
              " -0.002802960341796279,\n",
              " -0.005515917204320431,\n",
              " 0.00741241592913866,\n",
              " -0.024288037791848183,\n",
              " 0.020816480740904808,\n",
              " -0.02759244479238987,\n",
              " 0.0006428807973861694,\n",
              " -0.0027836738154292107,\n",
              " -0.012934762053191662,\n",
              " 0.03919001296162605,\n",
              " 0.0035904892720282078,\n",
              " -5.8311299653723836e-05,\n",
              " 0.0013251380296424031,\n",
              " -0.029006782919168472,\n",
              " -0.005866287276148796,\n",
              " -0.01431052666157484,\n",
              " 0.001002894015982747,\n",
              " -0.009938937611877918,\n",
              " 0.001612827298231423,\n",
              " -0.004146581050008535,\n",
              " 0.02527807280421257,\n",
              " -0.0053744837641716,\n",
              " 0.2509806752204895,\n",
              " -0.030832564458251,\n",
              " 0.014709113165736198,\n",
              " 0.013641931116580963,\n",
              " -0.007624566555023193,\n",
              " 0.030678272247314453,\n",
              " 0.005216978024691343,\n",
              " 0.0068338229320943356,\n",
              " 0.0051076882518827915,\n",
              " 0.011153982020914555,\n",
              " -0.016997769474983215,\n",
              " -0.011205412447452545,\n",
              " -0.03767281398177147,\n",
              " -0.0022372251842170954,\n",
              " -0.019093560054898262,\n",
              " -0.03026682883501053,\n",
              " -0.03288978338241577,\n",
              " -0.024930918589234352,\n",
              " -0.0115332817658782,\n",
              " 0.0022806196939200163,\n",
              " 0.03008682280778885,\n",
              " 0.003963360097259283,\n",
              " -0.010916116647422314,\n",
              " -0.018592113628983498,\n",
              " 0.008376737125217915,\n",
              " -0.018116381019353867,\n",
              " 0.005493416450917721,\n",
              " 0.013346205465495586,\n",
              " -0.014091947115957737,\n",
              " 0.006380592007189989,\n",
              " -0.019466431811451912,\n",
              " -0.03432983532547951,\n",
              " 0.014001944102346897,\n",
              " -0.027155285701155663,\n",
              " 0.006679531652480364,\n",
              " -0.01757636107504368,\n",
              " -0.002004181034862995,\n",
              " -0.008640318177640438,\n",
              " 0.005249121692031622,\n",
              " -0.0036837069783359766,\n",
              " 0.00824173167347908,\n",
              " 0.006628101225942373,\n",
              " -0.0015935407718643546,\n",
              " -0.000566538714338094,\n",
              " 0.023580867797136307,\n",
              " 0.014336242340505123,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how long the embedding vector is."
      ],
      "metadata": {
        "id": "U1hadXcQiOq5"
      },
      "id": "U1hadXcQiOq5"
    },
    {
      "cell_type": "code",
      "source": [
        "len(e)"
      ],
      "metadata": {
        "id": "3Ohnow38iuj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb644406-8181-4788-d5d8-2d26b8d3b3e5"
      },
      "id": "3Ohnow38iuj9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, that matches the official version:\n",
        ">The new embeddings have only 1536 dimensions, one-eighth the size of davinci-001 embeddings, making the new embeddings more cost effective in working with vector databases."
      ],
      "metadata": {
        "id": "X_4Hp5VKjnXG"
      },
      "id": "X_4Hp5VKjnXG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a Pandas DF with a column of text, we can use the `get_embedding` function to calculate the embeddings for all the text in the column."
      ],
      "metadata": {
        "id": "Dm1_rELVhRQO"
      },
      "id": "Dm1_rELVhRQO"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
        "    \"\"\"\n",
        "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
        "    \n",
        "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
        "    }"
      ],
      "metadata": {
        "id": "kg73ks73hEip"
      },
      "id": "kg73ks73hEip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you'd like to calculate the embeddings from scratch, uncomment the below line and run. Warning - it will take some time!"
      ],
      "metadata": {
        "id": "d-oqqBSN8KKX"
      },
      "id": "d-oqqBSN8KKX"
    },
    {
      "cell_type": "code",
      "source": [
        "# document_embeddings = compute_doc_embeddings(df)"
      ],
      "metadata": {
        "id": "k-07jQpM8Ios"
      },
      "id": "k-07jQpM8Ios",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cfe9c723-f838-4c75-8ed8-286b2e491a60",
      "metadata": {
        "id": "cfe9c723-f838-4c75-8ed8-286b2e491a60"
      },
      "source": [
        "But happily for us, OpenAI has calculated the embeddings for us so we don't have to! We download them and write a small function to load them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737266aa-cbe7-4691-87c1-fce8a31632f1",
      "metadata": {
        "id": "737266aa-cbe7-4691-87c1-fce8a31632f1"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
        "    \"\"\"\n",
        "    Read the document embeddings and their keys from a CSV.\n",
        "    \n",
        "    fname is the path to a CSV with exactly these named columns: \n",
        "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
        "    \"\"\"\n",
        "    \n",
        "    df = pd.read_csv(fname, header=0)\n",
        "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
        "    return {\n",
        "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
        "    }\n",
        "\n",
        "document_embeddings = load_embeddings(\n",
        "    \"https://cdn.openai.com/API/examples/data/olympics_sections_document_embeddings.csv\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9a8c713-c8a9-47dc-85a4-871ee1395566",
      "metadata": {
        "id": "b9a8c713-c8a9-47dc-85a4-871ee1395566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7abd76d-db3b-4134-815c-9e163d60fefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('2020 Summer Olympics', 'Summary'), [0.0037565305829048, -0.0061981128528714, -0.0087078781798481, -0.0071364338509738, -0.0025227521546185, 0.0150650832802057, -0.0218573585152626, -0.0057435631752014, -0.0066429222933948, -0.0316626504063606, 0.0160261318087577, 0.0097858104854822, -0.01212998945266, -0.0207404643297195, -0.021844370290637, -0.0121949249878525, 0.0238054282963275, -0.0157793760299682, -0.0024188549723476, -0.0130715575069189, -0.0248444005846977, 0.0085845002904534, -0.005526028573513, 0.0148053402081131, -0.0083052767440676, -0.0011428684229031, 0.0157014541327953, -0.0164936687797307, 0.0329613648355007, -0.020337862893939, -0.0105260778218507, 0.0108637437224388, -0.0094286641106009, 0.0089156720787286, -0.0033539291471242, -0.0162079520523548, -0.0153637873008847, -0.0127598661929368, 0.005344208329916, -0.0134416911751031, 0.0056494064629077, 0.0196365565061569, -0.0063831796869635, 0.0098182782530784, -0.0046623833477497, 0.0232339948415756, 0.0008096670499071, -0.0219352804124355, -0.0066688968800008, 0.0341042317450046, 0.0106364684179425, 0.0252470020204782, -0.022935289889574, -0.0150650832802057, -0.0076364385895431, -0.0189482383430004, -0.0161819774657487, -0.0029919126536697, 0.0124936290085315, 0.012740384787321, 0.0028198328800499, 0.0021558653097599, -0.0065520126372575, 0.0111364731565117, 0.011181928217411, 0.0027029486373066, -0.0188183672726154, 0.0080195590853691, -0.0285717099905014, -0.0053052469156682, 0.0025292455684393, 0.0117403753101825, 0.021896319463849, 0.0006079605082049, 0.0314029082655906, -0.0230391882359981, -0.0103182829916477, -0.0007581243407912, 0.0134676648303866, 0.0156495049595832, 0.0069611072540283, -0.0328055173158645, 0.0173118580132722, -0.0175586137920618, -0.0083052767440676, 0.0251431036740541, 0.0082857962697744, 0.0150780705735087, -0.0038539341185241, -0.0099611366167664, 0.0121105089783668, 0.0065487655811011, 0.0075585157610476, 0.0120650539174675, -0.0378185547888278, 0.0041688722558319, -0.0254547968506813, 0.0231430847197771, -0.0302600376307964, 0.0149871604517102, 0.0049903090111911, 0.0007252506329677, 0.0027516505215317, -0.0152858644723892, -0.0349094346165657, 0.0006968412781134, 0.0025048947427421, -0.0164417196065187, -0.0025065182708203, 0.0093507412821054, -0.010701403953135, -0.000737426104024, -0.001392870908603, -0.0684162601828575, -0.0255846679210662, -0.0078702075406908, 0.012597526423633, -0.0041786124929785, -0.0126235010102391, -0.0173118580132722, 0.0007207863382063, 0.0247015412896871, 0.0133248064666986, 0.0067468197084963, 0.020935270935297, -0.0175326392054557, -0.0159352216869592, 0.0038831550627946, 0.011818298138678, 0.0010316659463569, 0.0182469319552183, 0.0093377539888024, 0.004243548028171, 0.0289353504776954, -0.0066753905266523, 0.0427017174661159, -0.0079676108434796, -0.0008181898738257, -0.0217015128582716, -0.0031948366668075, -0.0040812091901898, 0.0138572789728641, -0.0223898310214281, 0.0252210274338722, 0.0102403601631522, 0.0459485054016113, 0.0150650832802057, -0.0044740699231624, 0.0335068218410015, 0.0142858549952507, 0.0140390992164611, 0.0103962058201432, 0.0202859137207269, 0.0340782590210437, 0.0126040205359458, 0.0148702766746282, 0.0309093948453664, 0.0211560521274805, -0.0128248017281293, -0.0048344633542001, 0.0196885056793689, -0.0029984060674905, 0.0050227767787873, -0.0278184562921524, -0.0336366929113864, 0.0064253876917064, 0.0375328361988067, 0.0027094422839581, 0.0130390897393226, -0.0217534601688385, -0.0152079416438937, 0.0004431861743796, -0.0377925783395767, 0.0156235303729772, 0.012441680766642, 0.0386237576603889, 0.0108053013682365, 0.0123832384124398, -0.0189482383430004, -0.007480592932552, 0.0043604327365756, -0.0127144111320376, 0.0331431850790977, 0.0074416315183043, -0.0238184165209531, 0.0032613957300782, 0.0117858303710818, 0.0034902940969914, 0.022156061604619, 0.0045909541659057, 0.0165845789015293, 0.011961156502366, 0.0090390499681234, 0.0168313346803188, -0.6366816163063049, -0.0210002064704895, 0.0139352018013596, 0.0021623589564114, 0.0280262492597103, 0.0159222353249788, 0.0152209289371967, 0.0172079615294933, -0.0269613042473793, 0.0139871509745717, -0.0198053903877735, -0.0023117109667509, 0.0079351430758833, -0.0204287730157375, -0.0061331773176789, -0.0232210084795951, 0.0009756589424796, 0.0073442282155156, -0.0122923292219638, -0.0136754596605896, -0.0093442481011152, -0.0006306880386546, -0.0146624818444252, 0.0162858739495277, -0.006558506283909, -0.0077922847121953, 0.0015681972727179, -0.0400003939867019, -0.0071818889118731, 0.04098741710186, -0.0012629994889721, 0.0285717099905014, 0.0117403753101825, 0.0106559488922357, 0.0352211259305477, -0.0281301476061344, -0.0364419184625148, 0.0416887216269969, 0.0216755382716655, 0.0287275556474924, 0.0091169727966189, 0.0071624079719185, -0.0052630389109253, -0.0093117803335189, 0.0129416855052113, 0.019870325922966, 0.0034578263293951, -0.0067468197084963, 0.0098117850720882, -0.0130520761013031, 0.0017841084627434, -0.0372211448848247, 0.0075974771752953, -0.0087598264217376, -0.0143897524103522, -0.0043247179128229, -0.0013165713753551, -0.0043117306195199, 0.0101494509726762, -0.0204027984291315, -0.0192339550703763, 0.0133507810533046, -0.0178832933306694, -0.0203508492559194, -0.0158832725137472, 0.0018587845843285, -0.0263249352574348, 0.0091429473832249, 0.0318704433739185, -0.0116299847140908, -0.0135715622454881, 0.0209482572972774, -0.0154027491807937, -0.0019902794156223, 0.0382860898971557, 0.0134676648303866, 0.0511173866689205, -0.0110910180956125, -0.0095845097675919, 0.011363748461008, 0.0035065279807895, 0.0002946457534562, 0.0027662608772516, -0.0121754445135593, 0.0086754104122519, -0.0292730145156383, -0.0437666662037372, 0.022519702091813, 0.0142598804086446, -0.0042240675538778, 0.0090130753815174, 0.0071104597300291, 0.020026171579957, -0.0039156228303909, 0.0067338324151933, 0.0112923188135027, -0.0063344780355691, -0.0090650245547294, 0.0250781681388616, -0.0240781586617231, -0.0076883872970938, 0.0093572353944182, 0.0100390594452619, -0.001402611262165, -0.0012362134875729, 0.0062695420347154, -0.022519702091813, 0.0097598358988761, 0.0463640913367271, -0.0108377691358327, 0.0055195349268615, 0.005441612098366, -0.0036721141077578, 0.0244288109242916, 0.0152079416438937, -0.0118702463805675, 0.0300782173871994, 0.0038441936485469, 0.0107923140749335, 0.0036363995168358, 0.0259483065456151, -0.0062533081509172, 0.0164936687797307, -0.0090130753815174, 0.021558653563261, 0.0328055173158645, 0.0111884213984012, -0.0112143959850072, -0.003584450809285, -0.0039253635331988, 0.0082208598032593, 0.0078247524797916, 0.0293249636888504, -0.0033961373846977, 0.0109351724386215, 0.0162079520523548, -0.0251431036740541, 0.0007211921620182, 0.0241820570081472, -0.0350652784109115, -0.0219872295856475, 0.007026043254882, -0.01167543977499, -0.0040909494273364, 0.0052987532690167, -0.0358185358345508, -0.0439225099980831, 0.0114027094095945, 0.0006578798638656, 0.0172339361160993, -0.0005901032127439, -0.0056753805838525, -0.0041299108415842, -0.0093767158687114, -0.0311171896755695, 0.0007565009291283, -0.0096819130703806, -0.0193898007273674, -0.0196365565061569, 0.0033506823237985, 0.005896161776036, 0.0078442329540848, -0.0111040053889155, -0.0122144054621458, 0.0080195590853691, -0.0032873700838536, -0.0184677150100469, 0.0054058972746133, 0.0077857910655438, -0.0339743606746196, 0.0059578507207334, 0.0075260479934513, -0.0063994135707616, 0.0045292652212083, 0.0054318718612194, 0.0088442424312233, -0.0125455781817436, -0.0168443210422992, 0.0124351875856518, -0.0021250208374112, 0.0260002557188272, -0.0137533824890851, -0.0309873186051845, -0.0039805588312447, 0.0105780260637402, -0.0065292851068079, 0.0163378231227397, -0.0023311916738748, 0.005526028573513, 0.001834433642216, 0.0055812238715589, 0.0225326884537935, 0.0275846868753433, -0.0142079321667552, 0.0108312750235199, 0.0015227422118186, 0.0141949448734521, -0.0140131246298551, -0.005740316119045, 0.0136884460225701, 0.0369354300200939, -0.0009618601179681, -0.0129092177376151, 0.011779336258769, 0.011662452481687, 0.0069091590121388, 0.0145975463092327, -0.0191820077598094, 0.0013628380838781, 0.0085845002904534, 0.0364419184625148, -0.0165456179529428, -0.0393510349094867, 0.0107598463073372, -0.0316886231303215, 0.0280781984329223, 0.00162258092314, 0.0162339266389608, -0.0054643396288156, -0.0250002462416887, -0.0120520666241645, -0.0350133329629898, 0.0205586440861225, -0.0225846376270055, -0.0239223130047321, 0.0095910038799047, -0.0075455289334058, 0.0154027491807937, 0.0190651230514049, 0.0221950244158506, -0.0243768636137247, -0.0002252457197755, -0.0112728383392095, 0.0177014730870723, 0.0166365280747413, 0.0044351085089147, 0.0087987883016467, -0.0075130611658096, 0.0356886647641658, -0.0046980981715023, 0.0124481748789548, -0.0094286641106009, 0.0349354073405265, 0.0023847636766731, 0.0072468244470655, -0.0232080202549695, 0.0428575649857521, -0.0144546879455447, -0.0148443020880222, 0.0076754000037908, -0.0191560331732034, -0.0032711362000554, -0.0336366929113864, 0.005357195623219, 0.0085780061781406, -0.0194157753139734, 0.0146754691377282, -0.0095195742323994, 0.0056039514020085, 0.0465459115803241, -0.0034026307985186, -0.00551304128021, 0.0097663300111889, 0.0029902891255915, 0.0076429322361946, 0.004042247775942, 0.0028311966452747, 0.0040747155435383, -0.0077792974188923, -0.0233508795499801, -0.0177274476736783, -0.0061818789690732, -0.0075520225800573, 0.0095455488190054, 0.0114481644704937, -0.0086494358256459, -0.0331951305270195, -0.001750017167069, -0.0043247179128229, 0.0269093550741672, -0.0358964577317237, -0.019714480265975, -0.0174936782568693, 0.0083312503993511, -0.0020860594231635, -0.0238054282963275, 0.0067792874760925, 0.0080260531976819, -0.0144157260656356, 0.0182079710066318, 0.0124481748789548, 0.0105195837095379, -0.0372730940580368, -0.0118118049576878, -0.0051039461977779, -0.0045519927516579, 0.0255846679210662, 0.0019707987084984, -0.0255197323858737, -0.0195456463843584, 0.0048344633542001, -0.0218313839286565, 0.0042078336700797, -0.0096884071826934, 0.0305197816342115, -0.0034708133898675, -0.0054091443307697, -0.0080390404909849, -0.0143118295818567, 0.0054026506841182, 0.0268833823502063, -0.0272470209747552, -0.0214417688548564, 0.0037013350520282, 0.0201430562883615, -0.0140001373365521, -0.0008441641693934, 0.0135455876588821, -0.0199482478201389, -0.0139481890946626, -0.0308054983615875, -0.0131235057488083, -0.0329873375594615, -0.0149741731584072, 0.0996373444795608, -0.0023441789671778, -0.0022906069643795, 0.0068117552436888, 0.01958460919559, 0.0107533521950244, 0.009935162961483, -0.0048636840656399, 0.011013095267117, 0.0219612549990415, -0.0228573679924011, 0.0045000445097684, -0.0145715717226266, 0.0249872580170631, 0.021922294050455, -0.0082403412088751, -0.0124806426465511, -0.0193248651921749, 0.0277405325323343, 0.0313769318163394, -0.0035812039859592, -0.0072078630328178, 0.0040357541292905, 0.0388834998011589, 0.0057468097656965, -0.023117110133171, 0.0196365565061569, 0.0141819575801491, 0.0220651514828205, -0.0136105231940746, -0.0045714736916124, -0.0087728137150406, 9.649039566284046e-05, 0.0055390154011547, -0.0148053402081131, 0.0181040745228528, 0.0171300396323204, 0.0119286887347698, 0.0279223527759313, -0.0172079615294933, 0.0331951305270195, -0.0143767651170492, -0.002092553069815, 0.0073052668012678, 0.0016355681000277, -0.0062468145042657, -0.0185716114938259, 0.0168443210422992, 0.0025178820360451, 0.0024204782675951, 0.022337881848216, -0.0008409173460677, -0.0281820949167013, -0.0324418768286705, -0.0185326505452394, 0.0139611763879656, -0.0131624676287174, -0.0180521253496408, -0.005129920784384, -0.0128183076158165, 0.0123507706448435, -0.0368834808468818, 0.0149222249165177, -0.0218573585152626, -0.0181690100580453, -0.0231690593063831, -0.02205216512084, -0.0055877175182104, -0.0225067157298326, -0.0087858010083436, -0.0130066219717264, -0.0242859534919261, -0.0289093758910894, 0.0146624818444252, 0.0090130753815174, -0.0093442481011152, 0.0074091637507081, -0.0351951532065868, 0.0047727744095027, 0.0138053307309746, -0.0140001373365521, -0.022026190534234, -0.0196755174547433, -0.0279223527759313, -0.0121234962716698, 0.0368575043976306, 0.0282859932631254, -0.0164027586579322, -0.0015032615046948, 0.0126170068979263, 0.0056266789324581, -0.0121754445135593, -0.0028977557085454, 0.0291691180318593, 0.0134936394169926, 0.0131105184555053, 0.0105130905285477, 0.0224807411432266, 0.0147923529148101, -0.0247145295143127, 0.0131559735164046, -0.0231300983577966, -0.012597526423633, 0.0114481644704937, -0.0070714983157813, 0.0128637626767158, 0.021740473806858, 0.0094481445848941, -0.0210391674190759, 0.0004131534078624, 0.0138183180242776, -0.0282600186765193, 0.0172469224780797, -0.0111169926822185, -0.022130087018013, 0.0109156919643282, 0.0054805735126137, 0.0492212623357772, 0.0043701729737222, -0.0128637626767158, -0.0103117898106575, -0.005201349966228, 0.0057046017609536, 0.011818298138678, -0.0209482572972774, -0.0098182782530784, -0.0191949941217899, -0.0196495447307825, -0.0010933548910543, -0.0138832535594701, 0.0076689068228006, 0.0109611470252275, -0.0290911961346864, 0.0073702023364603, -0.0190781094133853, 0.0106040006503462, -0.0148962503299117, -0.011623490601778, 0.0165845789015293, -0.0020909297745674, 0.003308474086225, -0.0178443323820829, 0.0238963384181261, 0.0056623932905495, 0.0045487461611628, -0.0227274969220161, -0.0181300491094589, -0.0002601486630737, -0.0036818543449044, 0.0106689361855387, 0.0137923434376716, -0.006772793829441, -0.020961245521903, 0.0066818841733038, -0.0156624913215637, -0.0105001032352447, -0.0305457543581724, -0.0250132326036691, 0.0136364977806806, 0.0200131833553314, 0.0099871112033724, -0.0120195988565683, 0.0161430165171623, 0.0049805683083832, -0.0160001572221517, 0.0002461468975525, -0.0162079520523548, -0.0066624032333493, -0.0134676648303866, -0.0178443323820829, -0.0036818543449044, 0.0267015621066093, -0.0221430752426385, -0.0066948710009455, -0.011363748461008, 0.0020714490674436, -0.0007536599878221, -0.0127144111320376, -0.0101559441536664, -0.0219742413610219, 0.0008352355216629, -0.0161819774657487, -0.0152988517656922, -0.007480592932552, -0.0195586346089839, -0.0272470209747552, 0.0030113933607935, 0.0004935113247483, 0.0166235398501157, -0.0104676354676485, -0.0189871992915868, -0.0126170068979263, 0.0040584816597402, 0.0240521840751171, -0.0210521556437015, 0.0013255000812932, -0.021454757079482, -0.021766448393464, 0.0134936394169926, 0.0088961916044354, 0.0037273094058036, 0.0186625216156244, 0.0013620264362543, -0.0133377937600016, -0.0042013400234282, 0.043299127370119, -0.0294548347592353, -0.0135066267102956, -0.0199222732335329, -0.0180780999362468, -0.0162988621741533, -0.011013095267117, 0.006448115222156, -0.0183897912502288, -0.022805418819189, 0.0111234858632087, -0.0008457875228486, 0.0204027984291315, -0.0163897722959518, -0.0117663498967885, -0.006798768416047, -0.0060325269587337, 0.0372471213340759, -0.0017419002251699, 0.0034350987989455, 0.0043084840290248, -4.68310736323474e-06, -0.0029659382998943, -0.0196625310927629, 0.0010462765349075, 0.011623490601778, 0.0472212433815002, 0.005766290705651, -0.0215716417878866, -0.0213118977844715, -0.0142209194600582, -0.0144936488941311, -0.0399744175374507, -0.0100975017994642, 0.0101494509726762, 0.0082598216831684, -0.0024805439170449, -0.0033409420866519, 0.006207853090018, -0.0073896832764148, 0.0306236781179904, -0.0301821157336235, -0.0142598804086446, -0.0028035989962518, -0.0131299989297986, 0.0036526334006339, 0.041117288172245, -0.0040812091901898, 0.0079286498948931, 0.0040747155435383, -0.0496628247201442, -0.0044805635698139, -0.0284418389201164, -0.0289353504776954, 0.0211430657655, -0.0049935556016862, 0.0261950623244047, -0.0066559095866978, -0.0071429274976253, 0.0280262492597103, 0.0053994036279618, 0.0141170220449566, -0.0029643150046467, 0.0018798885866999, 0.023402826860547, -0.0434549748897552, 0.005526028573513, 0.0189092773944139, 0.0395848043262958, 0.004412380978465, 0.0050195297226309, -0.0090715177357196, 0.000681419041939, -0.0135196140035986, 0.0117079075425863, 0.0191430449485778, 0.0048279697075486, -0.0005864505656063, -0.0120001183822751, -0.0175716020166873, -0.0221950244158506, -0.0239093266427516, -0.0192988906055688, 0.0130196083337068, -0.0232210084795951, -0.00551304128021, 0.0023652829695492, -0.0037240625824779, 0.0180391389876604, -0.0032938634976744, 0.0041331574320793, -0.0023571660276502, 0.0131040252745151, -0.0146754691377282, -0.0186105724424123, -0.0017159259878098, 0.0150910578668117, -0.0109546529129147, -0.0306236781179904, -0.0274807903915643, -0.0192469432950019, 0.0243768636137247, 0.011324786581099, -0.0081559242680668, -0.0187923926860094, 0.021013194695115, 0.0011266344226896, 0.0059253829531371, 0.0051753753796219, 0.0337146185338497, -0.0172339361160993, -0.0058344728313386, -0.0192988906055688, -0.0316366739571094, 0.0239353012293577, 0.005980578251183, 0.0184547267854213, 0.005753303412348, -0.0169612057507038, 0.0330652594566345, 0.002996782772243, 0.002912366297096, 0.0267535094171762, -0.0424419753253459, -0.0238184165209531, 0.0223248954862356, 0.001704562222585, 0.0003729744639713, 0.0041688722558319, -0.0243638753890991, 0.0063831796869635, -0.0093117803335189, 0.0237664673477411, -0.0061266836710274, 0.0068507166579365, 0.0096169775351881, 0.0215456672012805, 0.0384679101407527, 0.0083702122792601, 0.0076429322361946, -0.0255976542830467, 0.0098897079005837, -0.0116169974207878, -0.0178183577954769, -0.0179482288658618, -0.0051721287891268, 0.0422861315310001, 0.001798719051294, -0.0126364883035421, -0.0102663347497582, -0.011194915510714, 0.0001234793016919, -0.0096559394150972, 0.0061753853224217, 0.0270652007311582, 0.0266236383467912, 0.0354289188981056, 0.0098377587273716, 0.0186235606670379, -0.0112468637526035, 0.0044903038069605, -0.0127598661929368, -0.005597457755357, 0.044935505837202, -0.0113312806934118, 0.0062305806204676, -0.001280045020394, -0.0182599201798439, 0.0139222145080566, 0.0111494604498147, -0.0003914405533578, 0.0010113735916092, 0.0212339758872985, 0.0157663896679878, -0.002636389574036, -0.019870325922966, 0.0007569068111479, -0.0096624325960874, 0.0311951115727424, 0.0092013888061046, -0.0428835377097129, 0.0069351331330835, 0.0089026847854256, 0.0116299847140908, -0.0083896927535533, -0.0209482572972774, 0.0032516554929316, -0.0092013888061046, 0.0166625007987022, -0.0140650738030672, -0.0038441936485469, -0.000333607167704, -0.0275327377021312, 0.0314029082655906, -0.0178183577954769, -0.0112598510459065, 0.005837719887495, 0.0244028382003307, 0.003944844007492, -0.0163897722959518, 0.0034902940969914, -0.0267794840037822, -0.0217015128582716, 0.0041266637854278, -0.0007045523962005, -0.0018360570538789, -0.012896230444312, 0.0262210369110107, -0.0120520666241645, -0.0047727744095027, 0.0006396166863851, -0.0305197816342115, -0.0468835793435573, 0.0227534715086221, 0.0119806369766592, -0.0257534999400377, -0.0034708133898675, 0.0032484086696058, -0.0249612852931022, 0.0172209478914737, -0.0247405041009187, -0.0166365280747413, -0.0408835187554359, -0.0256496034562587, 0.0046201753430068, -0.0076624131761491, -0.0184287521988153, 0.0054253782145679, 0.0162598993629217, -0.0185196623206138, 0.0040487409569323, 0.2250411808490753, -0.0183768048882484, 0.0082143666222691, 0.0379484258592128, -0.0070714983157813, 0.011324786581099, 0.0402861125767231, 0.0103702321648597, -0.0190651230514049, 0.0142728677019476, -0.0105130905285477, -0.0006761430413462, 0.0079805981367826, 0.0066494159400463, 0.0113442670553922, 0.0012889737263321, -0.0148313147947192, -0.0225976258516311, -0.0349354073405265, 0.0274548158049583, 0.0026526234578341, 0.0170131549239158, -0.0026347662787884, 0.0090780118480324, -0.0068247425369918, 0.0216495636850595, 0.0187794063240289, 0.0163248367607593, -0.0129806473851203, -0.0118962209671735, 0.0141429966315627, -0.0177014730870723, -0.0094156768172979, 0.0065390253439545, -0.0103247771039605, -0.0141559839248657, -0.0031834729015827, 0.0062273340299725, 0.0147014437243342, 0.0165586043149232, 0.0086039807647466, 0.0157274268567562, 0.010389712639153, -0.0086624231189489, -0.0049253730103373, 0.0307016000151634, -0.0004208645259495, -0.0118962209671735, -0.0203508492559194, -0.0118118049576878, -0.0537148155272007, -0.0144157260656356, 0.0274288412183523, 0.0133248064666986, 0.0177404340356588, -0.0106494557112455, 0.0433251000940799, 0.0167274381965398, -0.0035747105721384, -0.0145585844293236, -0.0245716702193021, 0.0241301078349351, -0.0189742129296064, 0.0365717895328998, 0.0028701580595225, 0.0160261318087577, -0.0255067441612482, 0.0143897524103522, -0.0035519830416888, 0.0003167644899804, -0.006318244151771, -0.007013055961579, -0.0345457941293716, -0.0345977433025836, -0.0001695430692052, -0.0052273240871727, 0.0264028571546077, 0.0140131246298551, 0.0226625613868236, 0.0108053013682365, -8.484762474836316e-06, -0.0046299155801534, 0.0308054983615875, -0.0149352122098207, -0.0040325070731341, -0.0127079170197248, 0.0288574267178773, 0.0039221164770424, 0.0033896437380462, 0.0196885056793689, -0.0014618650311604, -0.0158183369785547, -0.0043993941508233, 0.0097533427178859, -0.0153508000075817, -0.0055097946897149, 0.0077143614180386, 0.0108247818425297, -0.0035779573954641, -0.0117988176643848, -0.0017240429297089, 0.0444160215556621, -0.010428674519062, -0.0074221510440111, -0.0005925382720306, -0.0346756651997566, -0.0268574077636003, -0.0055357688106596, 0.0318704433739185, -0.0261690896004438, 0.0009935162961483, -0.0134416911751031, 0.0181430354714393, -0.0103507507592439, -0.0020909297745674, 0.0052305711433291, -0.0130196083337068, -0.012441680766642, 0.0104481549933552, -0.0103377643972635, -0.0124027198180556, -0.0316366739571094, 0.0001897340116556, -0.0162858739495277, -0.0093507412821054, -0.0371951721608638, -0.0111299799755215, 0.0009845875902101, -0.0139871509745717, -0.0286496318876743, 0.0174027681350708, -0.0106299743056297, 0.010428674519062, -0.0045649800449609, 0.0017630043439567, -0.0144546879455447, 0.0165456179529428, -0.0107598463073372, -0.0143507905304431, -0.0128118144348263, -0.0134157165884971, -0.0287795048207044, 0.0274807903915643, 0.0101364636793732, 0.0078052715398371, -0.038675706833601, -0.0098572401329875, -0.0030227571260184, 0.0087793068960309, -0.0078247524797916, -0.0161040537059307, 0.0034967877436429, -0.0242859534919261, -0.0151689806953072, 0.0236625708639621, -0.0290392469614744, -0.0010641338303685, -0.0019123564707115, -0.0064708427526056, 0.0306756272912025, -0.0144027387723326, -0.0145326107740402, 0.0176884848624467, -0.0312210861593484, -0.0267794840037822, -0.0081624183803796, -0.1630145907402038, 0.0116949202492833, 0.0106169879436492, -0.012896230444312, 0.0107468590140342, 0.0009001711732707, 0.0021428782492876, -0.0258703846484422, 0.0014837807975709, -0.0068312361836433, 0.038675706833601, 0.020675528794527, -0.0249223224818706, -0.0375588126480579, 0.0045519927516579, -0.0093182735145092, -0.0144676752388477, 0.0177923832088708, 0.0290652215480804, 0.0226106122136116, 0.0422601550817489, -0.0160391181707382, -0.0074416315183043, 0.0068052615970373, -0.0150780705735087, 0.0253119375556707, -0.0053929104469716, -0.0209742318838834, 0.0269872788339853, 7.057953098410508e-06, -0.021013194695115, 0.021714499220252, 0.0105065973475575, 0.0186235606670379, -0.0028587942942976, 0.0021996970754116, -0.0026980785187333, -0.0290132723748683, -0.0205716304481029, 0.0353250242769718, -0.0127858398482203, -0.0087013840675354, -0.0254937577992677, -0.011013095267117, -0.0256106425076723, 0.0271690990775823, 0.010103995911777, -0.0085065774619579, 1.747683563735336e-05, -0.000375003699446, 0.0059318765997886, -0.0222209971398115, 0.0216625500470399, -0.0066753905266523, 0.0158313252031803, -0.006785781122744, 0.0219352804124355, 0.0006680260412395, -0.0003699305816553, 0.0103637380525469, -0.02140280790627, -0.0188443418592214, 0.0225716512650251, -0.0302860122174024, -0.0126429814845323, 0.0138183180242776, -0.0176495239138603, -0.0056494064629077, -0.0308054983615875, 0.0124546680599451, 0.020675528794527, 0.005214337259531, 0.021714499220252, -0.0114741390570998, 0.0111169926822185, 0.0036493865773081, 0.0045779673382639, 0.0030649651307612, 0.0099871112033724, 0.0144417006522417, -0.0297145787626504, 0.0523381792008876, -0.0192209687083959, -0.0267015621066093, 0.000866079935804, 0.0246236193925142, 0.0087728137150406, 0.0173638071864843, -0.0424679517745971, -0.0095845097675919, 0.0046039414592087, -0.0287015810608863, -0.0001568603038322, 0.0008774437010288, 0.0058409664779901, 0.0182209592312574, -0.0093377539888024, -0.001788978697732, 0.010091008618474, -0.0179482288658618, -0.0001990685123018, -0.0086169680580496, -0.012117002159357, 0.0379224494099617, 0.0324418768286705, 0.0032175641972571, -0.0034578263293951, 0.0320782363414764, 0.0062630488537251, 0.0051071932539343, -0.0289872977882623, 0.0087013840675354, 0.0008506576996296, 0.0247664768248796, -0.0106429615989327, 0.019714480265975, 0.0297925006598234, -0.0034188649151474, 0.0131949353963136, 0.0097858104854822, 0.0188313536345958, -0.0006327172741293, -0.0210391674190759, 0.0211560521274805, -0.0178832933306694, -0.0153508000075817, -0.0862346142530441, -0.0009026062907651, 0.0078572202473878, 0.041428979486227, 0.0296626295894384, 0.0414030030369758, 0.0112793315201997, 0.0260002557188272, 0.0227145086973905, 0.0315847247838974, -0.0091559346765279, -0.0121819376945495, 0.0155456075444817, 0.0001502652739873, 0.0242469925433397, -0.0209222845733165, 0.0057338224723935, -0.0172988716512918, 0.0131884412840008, 0.0130325956270098, -0.0008961127023212, -0.0178053695708513, 0.0149222249165177, -0.0248963497579097, -0.0167144499719142, -0.0320782363414764, -0.0377146564424037, 0.0341302044689655, 0.0042792628519237, 0.0096169775351881, -0.000118609124911, -0.0038539341185241, 0.0149352122098207, -0.0181819964200258, 0.0108312750235199, 0.0024967778008431, -0.0237145200371742, 0.0186625216156244, 0.0134546775370836, -0.0246495939791202, 0.0128377890214324, 0.0078572202473878, 0.0164417196065187, -0.0058052521198987, 0.0069546140730381, -0.0008855606429278, -0.0135066267102956, 0.0026120387483388, 0.0032256811391562, -0.0141819575801491, -0.0437147170305252, 0.0014748522080481, -0.0060000591911375, -0.0018750184681266, -0.0021331377793103, -0.0028928855899721, 0.023402826860547, 0.0100455535575747, -0.0427017174661159, 0.0139611763879656, 0.0161430165171623, 0.0197924021631479, -0.012428693473339, -0.0027370399329811, 0.0306496527045965, 0.011662452481687, -0.0134157165884971, -0.0120390793308615, 0.0188962891697883, -0.0167404245585203, -0.006688377354294, 0.0225716512650251, -0.0225456766784191, 0.001824693288654, -0.0093117803335189, 0.0079870913177728, -0.0128637626767158, -0.0170780904591083, 0.0242469925433397, -0.0193248651921749, -0.0028669112361967, -0.0065422724001109, -0.0167534109205007, 0.0073182536289095, 0.0057435631752014, 0.0175066664814949, -0.0064773363992571, 0.0067922747693955, 0.0207144897431135, -0.0228963289409875, -0.011194915510714, 0.0221950244158506, 0.0261171404272317, 0.0022613857872784, -0.0024432057980448, 0.0230651628226041, -0.0005592587403953, -0.0235067252069711, 0.0002753679582383, 0.0256366152316331, -0.0265457164496183, -0.0137533824890851, -0.0790137648582458, 0.0337405912578105, 0.0249353107064962, -0.0188053790479898, 0.0111429672688245, 0.0140910474583506, 0.0308054983615875, -0.0054351184517145, -0.0086819035932421, -0.0126040205359458, -0.0383899882435798, 0.0091689210385084, -0.0117468684911727, 0.0099546434357762, -0.0369614027440547, -0.0329094156622886, 0.0210261810570955, 0.0141040347516536, 0.0031136670149862, -0.0067922747693955, 0.0002187521458836, 0.0075195543467998, 0.0154806720092892, 0.0268314331769943, -0.0109027046710252, 6.73707909299992e-05, -0.0195586346089839, 0.0207534506916999, -0.0213638469576835, -0.0145845590159296, 0.0166625007987022, 0.0047922548837959, -0.0046331626363098, 0.0099091883748769, -0.0133897420018911, -0.0071039660833776, 0.0168832838535308, -0.0130131151527166, 0.0014399492647498, 0.0241301078349351, -0.0137533824890851, -0.0104871159419417, -0.0126235010102391, 0.0073507218621671, -0.0176625121384859, 0.020961245521903, -0.0038928955327719, 0.0050519979558885, 0.0015511516248807, 0.0114481644704937, -0.0092273633927106, 0.0107728336006402, -0.005753303412348, -0.0074221510440111, 0.0372730940580368, -0.0167923737317323, 0.011324786581099, 0.0075390352867543, 0.0019350840011611, -0.0116429720073938, 0.0364938639104366, 0.0005702166236005, 0.0291171688586473, -0.0144027387723326, 0.0330652594566345, -0.0063539585098624, -0.022935289889574, 0.0012329666642472, -0.0057305758818984, -0.0057110949419438, 0.0051201800815761, 0.0245327092707157, 0.0048279697075486, 0.0334808491170406, -0.0160650927573442, 0.0041948463767766, 0.0126754492521286, -0.0074935802258551, -0.0246366057544946, 0.0048539438284933, 0.0014050463214516, 0.0027061954606324, -0.0433251000940799, 0.021740473806858, 0.0016623539850115, -0.023117110133171, -0.0216755382716655, 0.0153508000075817, -0.0409094952046871, 0.0091754151508212, -0.003237044904381, 0.0044610830955207, 0.0133118191733956, 0.0116949202492833, 0.0136494850739836, 0.0056494064629077, -0.0038474404718726, -0.0056071979925036, 0.0363120473921299, 0.0149611858651041, 0.0258314236998558, -0.0037240625824779, -0.0018035891698673, -0.0158183369785547, -0.0156105430796742, -0.0007151044555939, -0.0226365868002176, -0.0249353107064962, 0.0023604128509759, 0.0151949543505907, -0.002644506515935, 0.0398185737431049, -0.0158702861517667, 0.0166365280747413, -0.0029594446532428, -0.0046136816963553, 0.0028928855899721, -0.0206105932593345, -0.0046429028734564, 0.0145326107740402, 0.0184157658368349, 0.0180261507630348, -0.0126884365454316, -0.0197794158011674, 0.0338964387774467, -0.0274028666317462, 0.0162988621741533, -0.0272210463881492, -0.0052597918547689, -0.0026818446349352, 0.0142209194600582, -0.0013806953793391, -0.021091116592288, -0.0177923832088708, 0.0146494945511221, -0.0130261024460196, 0.0029091194737702, 0.0332470797002315, 0.0480264462530612, 0.0259483065456151, 0.0269353296607732, 0.010428674519062, 0.0225456766784191, 0.0309613440185785, 0.0045000445097684, -0.0180521253496408, 0.0080325463786721, -0.0334288999438285, -0.0083052767440676, 0.0027272994630038, -0.0214937180280685, -0.0285717099905014, -0.0124546680599451, -0.0336886420845985, 0.0121819376945495, 0.0135715622454881, 0.0243249144405126, -0.0299483463168144, 0.0119027141481637, 0.0269613042473793, -0.0212339758872985, 0.0207144897431135, 0.0172469224780797, 0.0199742224067449, 0.0195586346089839, 0.0137923434376716, -0.0043604327365756, -0.019714480265975, -0.0316626504063606, 0.0057630436494946, -0.0010065033566206, -0.0094156768172979, -0.0189092773944139, 0.0002353919262532, -0.0031104201916605, 0.0057857711799442, 0.0152728771790862, 0.0175716020166873, 0.0103247771039605, 0.0009448144701309, -0.0063474648632109, -0.0268574077636003, -0.0341302044689655, -0.0148962503299117, 0.0188183672726154, -0.0134806521236896, -0.0024594396818429, -0.0374029651284217])\n"
          ]
        }
      ],
      "source": [
        "# An example embedding:\n",
        "example_entry = list(document_embeddings.items())[0]\n",
        "print(example_entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa32cf88-9edb-4dc6-b4cf-a16a8de7d304",
      "metadata": {
        "tags": [],
        "id": "aa32cf88-9edb-4dc6-b4cf-a16a8de7d304"
      },
      "source": [
        "So we have split our custom data into sections, and calculated embedding vectors for each. Next we will use these embeddings to answer our users' questions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Each time we receive a question\n",
        "\n",
        "* We calculate an embedding vector for the question (again using the same `text-embedding-ada-002` model) with the `get_embedding` funtion we defined above.\n",
        "* For each section in our custom dataset, we calculate the cosine similarity between that section's embedding vector and the question's embedding vector\n",
        "* We rank the sections from most-cosine-similar to the question to least-cosine-similar"
      ],
      "metadata": {
        "id": "ifOWmFZakFg8"
      },
      "id": "ifOWmFZakFg8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first define a couple of helper functions."
      ],
      "metadata": {
        "id": "UrIamAaN4YdS"
      },
      "id": "UrIamAaN4YdS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcd680e9-f194-4180-b14f-fc357498eb92",
      "metadata": {
        "id": "dcd680e9-f194-4180-b14f-fc357498eb92"
      },
      "outputs": [],
      "source": [
        "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
        "    \"\"\"\n",
        "    Returns the similarity between two vectors.\n",
        "    \n",
        "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
        "    \"\"\"\n",
        "    return np.dot(np.array(x), np.array(y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
        "    \"\"\"\n",
        "    Calc the embedding for the supplied query and calc the cosine\n",
        "    similarity against all the pre-calculated section embeddings. \n",
        "    \n",
        "    Return the list of sections, sorted by relevance in descending order.\n",
        "    \"\"\"\n",
        "    query_embedding = get_embedding(query)\n",
        "    \n",
        "    document_similarities = sorted([\n",
        "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
        "    ], reverse=True)\n",
        "    \n",
        "    return document_similarities"
      ],
      "metadata": {
        "id": "29JmypzN4Stb"
      },
      "id": "29JmypzN4Stb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test these functions out."
      ],
      "metadata": {
        "id": "6I5LexJy5K-j"
      },
      "id": "6I5LexJy5K-j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a27d73-f47f-480d-b336-079414f749cb",
      "metadata": {
        "id": "e3a27d73-f47f-480d-b336-079414f749cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd39ff49-c12f-4d37-fcac-e346d3755703"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.8848838116467932,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')),\n",
              " (0.8634516122222147,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's pole vault\", 'Summary')),\n",
              " (0.8616689251543945,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's long jump\", 'Summary')),\n",
              " (0.8560916109708381,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's triple jump\", 'Summary')),\n",
              " (0.8469427954223732,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's 110 metres hurdles\",\n",
              "   'Summary'))]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "order_document_sections_by_query_similarity(\"Who won the men's high jump?\", document_embeddings)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "729c2ce7-8540-4ab2-bb3a-76c4dfcb689c",
      "metadata": {
        "id": "729c2ce7-8540-4ab2-bb3a-76c4dfcb689c"
      },
      "outputs": [],
      "source": [
        "order_document_sections_by_query_similarity(\"Who won the women's high jump?\", document_embeddings)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf71fae-abb1-46b2-a483-c1b2f1a915c2",
      "metadata": {
        "id": "3cf71fae-abb1-46b2-a483-c1b2f1a915c2"
      },
      "source": [
        "We can see that the most relevant sections for each question include the summaries for the Men's and Women's high jump competitions - which is exactly what we would expect."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0efa0f6-4469-457a-89a4-a2f5736a01e0",
      "metadata": {
        "id": "a0efa0f6-4469-457a-89a4-a2f5736a01e0"
      },
      "source": [
        "#### Starting from the most-cosine-similar section, include as many sections into the prompt as can fit into the context window\n",
        "\n",
        "\n",
        "Once we've calculated the most relevant pieces of context, we construct a prompt by simply prepending them to the supplied query. It is helpful to use a query separator to help the model distinguish between separate pieces of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b763ace2-1946-48e0-8ff1-91ba335d47a0",
      "metadata": {
        "id": "b763ace2-1946-48e0-8ff1-91ba335d47a0"
      },
      "outputs": [],
      "source": [
        "# We are using up 300 tokens for the output so we have a \n",
        "# budget of ~3700 tokens we can use. But that's overkill\n",
        "# in this example and I don't want a big bill from OpenAI\n",
        "# - remember, they charge by the token! -\n",
        "# so we will just use 500 tokens.\n",
        "MAX_SECTION_LEN = 500\n",
        "\n",
        "# It helps the LLM if we provide the sections with a nice\n",
        "# separator.\n",
        "\n",
        "SEPARATOR = \"\\n* \""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HEADER = \"\"\"\n",
        "Answer the question as truthfully as possible using the provided context, \n",
        "and if the answer is not contained within the text below, \n",
        "say \"I don't know.\"\\n\\nContext:\\n\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QtWjlkMKDvVb"
      },
      "id": "QtWjlkMKDvVb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c5c0509-eeb9-4552-a5d4-6ace04ef73dd",
      "metadata": {
        "id": "0c5c0509-eeb9-4552-a5d4-6ace04ef73dd"
      },
      "outputs": [],
      "source": [
        "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Fetch relevant \n",
        "    \"\"\"\n",
        "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
        "    \n",
        "    chosen_sections = []\n",
        "    chosen_sections_len = 0\n",
        "    chosen_sections_indexes = []\n",
        "     \n",
        "    for _, section_index in most_relevant_document_sections:\n",
        "        # Add sections until we run out of context window        \n",
        "        document_section = df.loc[section_index]\n",
        "        \n",
        "        chosen_sections_len += document_section.tokens \n",
        "        if chosen_sections_len > MAX_SECTION_LEN:\n",
        "            break\n",
        "            \n",
        "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
        "        chosen_sections_indexes.append(str(section_index))\n",
        "            \n",
        "    # Useful diagnostic information\n",
        "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
        "    print(\"\\n\".join(chosen_sections_indexes))\n",
        "        \n",
        "    return HEADER + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f614045a-3917-4b28-9643-7e0c299ec1a7",
      "metadata": {
        "id": "f614045a-3917-4b28-9643-7e0c299ec1a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd25a362-c919-4f78-bbf8-9c5f28b47600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected 2 document sections:\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's long jump\", 'Summary')\n",
            "===\n",
            " \n",
            "Answer the question as truthfully as possible using the provided context, \n",
            "and if the answer is not contained within the text below, \n",
            "say \"I don't know.\"\n",
            "\n",
            "Context:\n",
            "\n",
            "\n",
            "* The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium. 33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021). Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance where the athletes of different nations had agreed to share the same medal in the history of Olympics. Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a 'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg of Sweden (1984 to 1992).\n",
            "* The men's long jump event at the 2020 Summer Olympics took place between 31 July and 2 August 2021 at the Japan National Stadium. Approximately 35 athletes were expected to compete; the exact number was dependent on how many nations use universality places to enter athletes in addition to the 32 qualifying through time or ranking (1 universality place was used in 2016). 31 athletes from 20 nations competed. Miltiadis Tentoglou won the gold medal, Greece's first medal in the men's long jump. Cuban athletes Juan Miguel Echevarría and Maykel Massó earned silver and bronze, respectively, the nation's first medals in the event since 2008.\n",
            "\n",
            " Q: Who won the 2020 Summer Olympics men's high jump?\n",
            " A:\n"
          ]
        }
      ],
      "source": [
        "prompt = construct_prompt(\n",
        "    \"Who won the 2020 Summer Olympics men's high jump?\",\n",
        "    document_embeddings,\n",
        "    df\n",
        ")\n",
        "\n",
        "print(\"===\\n\", prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b022fd4-0a3c-4ae1-bed1-4c80e4f0fb56",
      "metadata": {
        "tags": [],
        "id": "1b022fd4-0a3c-4ae1-bed1-4c80e4f0fb56"
      },
      "source": [
        "We have now obtained the sections that are most relevant to the question. As a final step, let's put it all together to get an answer to the question.\n",
        "\n",
        "#### Send the prompt into `text-davinci-003`!\n",
        "\n",
        "Now that we've retrieved the relevant sections and constructed our prompt, we can finally answer the user's query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0edfec7-9243-4573-92e0-253d31c771ad",
      "metadata": {
        "id": "b0edfec7-9243-4573-92e0-253d31c771ad"
      },
      "outputs": [],
      "source": [
        "COMPLETIONS_API_PARAMS = {\n",
        "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
        "    \"temperature\": 0.0,\n",
        "    \"max_tokens\": 300,\n",
        "    \"model\": COMPLETIONS_MODEL,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c1c9a69-848e-4099-a90d-c8da36c153d5",
      "metadata": {
        "id": "9c1c9a69-848e-4099-a90d-c8da36c153d5"
      },
      "outputs": [],
      "source": [
        "def answer_query_with_context(\n",
        "    query: str,\n",
        "    df: pd.DataFrame,\n",
        "    document_embeddings: dict[(str, str), np.array],\n",
        "    show_prompt: bool = True\n",
        ") -> str:\n",
        "    prompt = construct_prompt(\n",
        "        query,\n",
        "        document_embeddings,\n",
        "        df\n",
        "    )\n",
        "    \n",
        "    if show_prompt:\n",
        "        print(prompt)\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "                prompt=prompt,\n",
        "                **COMPLETIONS_API_PARAMS\n",
        "            )\n",
        "\n",
        "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c233e449-bf33-4c9e-b095-6a4dd278c8fd",
      "metadata": {
        "id": "c233e449-bf33-4c9e-b095-6a4dd278c8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "ba2b395c-eb3d-4369-afcf-f80e2fed9889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected 2 document sections:\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's long jump\", 'Summary')\n",
            "\n",
            "Answer the question as truthfully as possible using the provided context, \n",
            "and if the answer is not contained within the text below, \n",
            "say \"I don't know.\"\n",
            "\n",
            "Context:\n",
            "\n",
            "\n",
            "* The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium. 33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021). Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance where the athletes of different nations had agreed to share the same medal in the history of Olympics. Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a 'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg of Sweden (1984 to 1992).\n",
            "* The men's long jump event at the 2020 Summer Olympics took place between 31 July and 2 August 2021 at the Japan National Stadium. Approximately 35 athletes were expected to compete; the exact number was dependent on how many nations use universality places to enter athletes in addition to the 32 qualifying through time or ranking (1 universality place was used in 2016). 31 athletes from 20 nations competed. Miltiadis Tentoglou won the gold medal, Greece's first medal in the men's long jump. Cuban athletes Juan Miguel Echevarría and Maykel Massó earned silver and bronze, respectively, the nation's first medals in the event since 2008.\n",
            "\n",
            " Q: Who won the 2020 Summer Olympics men's high jump?\n",
            " A:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Gianmarco Tamberi and Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "answer_query_with_context(\"Who won the 2020 Summer Olympics men's high jump?\", df, document_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's ask a question for an Olympics event that never happened!"
      ],
      "metadata": {
        "id": "wF_dng2dEJFH"
      },
      "id": "wF_dng2dEJFH"
    },
    {
      "cell_type": "code",
      "source": [
        "answer_query_with_context(\"Who won the 2019 Summer Olympics men's high jump?\", df, document_embeddings)"
      ],
      "metadata": {
        "id": "vC9LfXISED8l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "c581c28d-cd0f-4ccc-953a-1034dc728826"
      },
      "id": "vC9LfXISED8l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected 2 document sections:\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's long jump\", 'Summary')\n",
            "\n",
            "Answer the question as truthfully as possible using the provided context, \n",
            "and if the answer is not contained within the text below, \n",
            "say \"I don't know.\"\n",
            "\n",
            "Context:\n",
            "\n",
            "\n",
            "* The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium. 33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021). Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance where the athletes of different nations had agreed to share the same medal in the history of Olympics. Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a 'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg of Sweden (1984 to 1992).\n",
            "* The men's long jump event at the 2020 Summer Olympics took place between 31 July and 2 August 2021 at the Japan National Stadium. Approximately 35 athletes were expected to compete; the exact number was dependent on how many nations use universality places to enter athletes in addition to the 32 qualifying through time or ranking (1 universality place was used in 2016). 31 athletes from 20 nations competed. Miltiadis Tentoglou won the gold medal, Greece's first medal in the men's long jump. Cuban athletes Juan Miguel Echevarría and Maykel Massó earned silver and bronze, respectively, the nation's first medals in the event since 2008.\n",
            "\n",
            " Q: Who won the 2019 Summer Olympics men's high jump?\n",
            " A:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good, it is trying to be humble and say \"I don't know\"."
      ],
      "metadata": {
        "id": "8eDW-Li0lo9T"
      },
      "id": "8eDW-Li0lo9T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's change the header to \"allow\" it to lie 👀 and see if it takes the bait."
      ],
      "metadata": {
        "id": "QmSnLQNbEb8n"
      },
      "id": "QmSnLQNbEb8n"
    },
    {
      "cell_type": "code",
      "source": [
        "HEADER = \"\"\"\n",
        "Answer the question using the provided context.\"\\n\\nContext:\\n\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pJvZaDWfEbY9"
      },
      "id": "pJvZaDWfEbY9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_query_with_context(\"Who won the 2019 Summer Olympics men's high jump?\", df, document_embeddings)"
      ],
      "metadata": {
        "id": "0D5ixg3aEpIB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "0d78f229-1866-4768-b594-2c5cfc938448"
      },
      "id": "0D5ixg3aEpIB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected 2 document sections:\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's long jump\", 'Summary')\n",
            "\n",
            "Answer the question using the provided context.\"\n",
            "\n",
            "Context:\n",
            "\n",
            "\n",
            "* The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium. 33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021). Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance where the athletes of different nations had agreed to share the same medal in the history of Olympics. Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a 'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg of Sweden (1984 to 1992).\n",
            "* The men's long jump event at the 2020 Summer Olympics took place between 31 July and 2 August 2021 at the Japan National Stadium. Approximately 35 athletes were expected to compete; the exact number was dependent on how many nations use universality places to enter athletes in addition to the 32 qualifying through time or ranking (1 universality place was used in 2016). 31 athletes from 20 nations competed. Miltiadis Tentoglou won the gold medal, Greece's first medal in the men's long jump. Cuban athletes Juan Miguel Echevarría and Maykel Massó earned silver and bronze, respectively, the nation's first medals in the event since 2008.\n",
            "\n",
            " Q: Who won the 2019 Summer Olympics men's high jump?\n",
            " A:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Italian athlete Gianmarco Tamberi and Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WOW! We caught it in the act! 😁\n",
        "\n",
        "If we don't explicitly tell it not to, it will \"hallucinate\"! That little extra phrase in the header - `as truthfully as possible` - changes its behavior!!!\n",
        "\n"
      ],
      "metadata": {
        "id": "7M4UdUiiE0N1"
      },
      "id": "7M4UdUiiE0N1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Examples\n",
        "\n",
        "Let's have some fun and try some more examples. First, let's go back to the old header."
      ],
      "metadata": {
        "id": "hpt_5uvMN9XQ"
      },
      "id": "hpt_5uvMN9XQ"
    },
    {
      "cell_type": "code",
      "source": [
        "HEADER = \"\"\"\n",
        "Answer the question as truthfully as possible using the provided context, \n",
        "and if the answer is not contained within the text below, \n",
        "say \"I don't know.\"\\n\\nContext:\\n\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Cy0bSofFtX2y"
      },
      "id": "Cy0bSofFtX2y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1127867b-2884-44bb-9439-0e8ae171c835",
      "metadata": {
        "id": "1127867b-2884-44bb-9439-0e8ae171c835"
      },
      "outputs": [],
      "source": [
        "query = \"Why was the 2020 Summer Olympics originally postponed?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "720d9e0b-b189-4101-91ee-babf736199e6",
      "metadata": {
        "id": "720d9e0b-b189-4101-91ee-babf736199e6"
      },
      "outputs": [],
      "source": [
        "query = \"In the 2020 Summer Olympics, how many gold medals did the country which won the most medals win? Explain step by step.\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8e51cc-e4eb-4557-9e09-2929d4df5b7f",
      "metadata": {
        "id": "4e8e51cc-e4eb-4557-9e09-2929d4df5b7f"
      },
      "outputs": [],
      "source": [
        "query = \"What was unusual about the men’s shotput competition?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c83519-e3c6-4c44-8b4a-98cbb3a5f5ba",
      "metadata": {
        "id": "37c83519-e3c6-4c44-8b4a-98cbb3a5f5ba"
      },
      "outputs": [],
      "source": [
        "query = \"In the 2020 Summer Olympics, how many bronze medals did Italy win?\"\n",
        "\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to trick it a bit! 😉"
      ],
      "metadata": {
        "id": "vgoHdKMvRlGp"
      },
      "id": "vgoHdKMvRlGp"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"In the 2020 Summer Olympics, how many titanium medals did Italy win?\"\n",
        "\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ],
      "metadata": {
        "id": "MVfrG8U5Rpku"
      },
      "id": "MVfrG8U5Rpku",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice job, `text-davinci-003`!!! 👏"
      ],
      "metadata": {
        "id": "IIQo2DsJR6rU"
      },
      "id": "IIQo2DsJR6rU"
    },
    {
      "cell_type": "markdown",
      "id": "7b48d155-d2d4-447c-ab8e-5a5b4722b07c",
      "metadata": {
        "id": "7b48d155-d2d4-447c-ab8e-5a5b4722b07c"
      },
      "source": [
        "## Conclusion\n",
        "By combining pretrained contextual embeddings and `text-davinci-003`, we have created a question-answering model which can answer questions in natural language using a custom dataset. It also **tries** not to make stuff up and says \"I don't know\" when it doesn't know the answer! **But this is not guaranteed.** \n",
        "\n",
        "For this example we have used a dataset of Wikipedia articles, but that dataset could be replaced with books, articles, documentation, service manuals, or much much more. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "How you can use this approach to \"understand\" a dense 56-page legal document:\n",
        "A fun [example](https://www.youtube.com/watch?v=ih9PBGVVOO4)\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pM5FjVPUCAuT"
      },
      "id": "pM5FjVPUCAuT"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.9 ('openai')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}